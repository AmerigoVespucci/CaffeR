Log file created at: 2015/08/12 10:54:05
Running on machine: AbbaHostedByChayim
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0812 10:54:05.553783 16297 caffe.cpp:117] Use CPU.
I0812 10:54:05.554018 16297 caffe.cpp:121] Starting Optimization
I0812 10:54:05.554071 16297 solver.cpp:32] Initializing solver from parameters: 
train_net: "/home/abba/caffe/examples/simple/train.prototxt"
test_net: "/home/abba/caffe/examples/simple/train.prototxt"
test_iter: 100
test_interval: 1000
base_lr: 0.0001
display: 500
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 2000
snapshot_prefix: "/home/abba/caffe/examples/simple/simple"
solver_mode: CPU
I0812 10:54:05.554162 16297 solver.cpp:61] Creating training net from train_net file: /home/abba/caffe/examples/simple/train.prototxt
I0812 10:54:05.554360 16297 net.cpp:287] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0812 10:54:05.554386 16297 net.cpp:287] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0812 10:54:05.554445 16297 net.cpp:42] Initializing net from parameters: 
name: "LogisticRegressionNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/abba/caffe/examples/simple/train_list.txt"
    batch_size: 5
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "data"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "loss"
}
I0812 10:54:05.554646 16297 net.cpp:67] Memory required for data: 0
I0812 10:54:05.554695 16297 layer_factory.hpp:74] Creating layer data
I0812 10:54:05.554726 16297 net.cpp:90] Creating Layer data
I0812 10:54:05.554744 16297 net.cpp:368] data -> data
I0812 10:54:05.554793 16297 net.cpp:368] data -> label
I0812 10:54:05.554811 16297 net.cpp:120] Setting up data
I0812 10:54:05.554826 16297 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/abba/caffe/examples/simple/train_list.txt
I0812 10:54:05.554977 16297 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
I0812 10:54:05.555188 16297 hdf5_data_layer.cpp:29] Loading HDF5 file: /home/abba/caffe/examples/simple/train.h5
I0812 10:54:05.556563 16297 hdf5_data_layer.cpp:68] Successully loaded 100 rows
I0812 10:54:05.556605 16297 net.cpp:127] Top shape: 5 2 (10)
I0812 10:54:05.556618 16297 net.cpp:127] Top shape: 5 1 (5)
I0812 10:54:05.556627 16297 net.cpp:133] Memory required for data: 60
I0812 10:54:05.556640 16297 layer_factory.hpp:74] Creating layer fc1
I0812 10:54:05.556663 16297 net.cpp:90] Creating Layer fc1
I0812 10:54:05.556674 16297 net.cpp:410] fc1 <- data
I0812 10:54:05.556696 16297 net.cpp:368] fc1 -> fc1
I0812 10:54:05.556713 16297 net.cpp:120] Setting up fc1
I0812 10:54:05.557097 16297 net.cpp:127] Top shape: 5 2 (10)
I0812 10:54:05.557109 16297 net.cpp:133] Memory required for data: 100
I0812 10:54:05.557127 16297 layer_factory.hpp:74] Creating layer loss
I0812 10:54:05.557142 16297 net.cpp:90] Creating Layer loss
I0812 10:54:05.557152 16297 net.cpp:410] loss <- fc1
I0812 10:54:05.557164 16297 net.cpp:410] loss <- label
I0812 10:54:05.557178 16297 net.cpp:368] loss -> loss
I0812 10:54:05.557191 16297 net.cpp:120] Setting up loss
I0812 10:54:05.557204 16297 layer_factory.hpp:74] Creating layer loss
I0812 10:54:05.557231 16297 net.cpp:127] Top shape: (1)
I0812 10:54:05.557240 16297 net.cpp:129]     with loss weight 1
I0812 10:54:05.557260 16297 net.cpp:133] Memory required for data: 104
I0812 10:54:05.557271 16297 net.cpp:192] loss needs backward computation.
I0812 10:54:05.557281 16297 net.cpp:192] fc1 needs backward computation.
I0812 10:54:05.557291 16297 net.cpp:194] data does not need backward computation.
I0812 10:54:05.557298 16297 net.cpp:235] This network produces output loss
I0812 10:54:05.557312 16297 net.cpp:482] Collecting Learning Rate and Weight Decay.
I0812 10:54:05.557322 16297 net.cpp:247] Network initialization done.
I0812 10:54:05.557353 16297 net.cpp:248] Memory required for data: 104
I0812 10:54:05.557504 16297 solver.cpp:154] Creating test net (#0) specified by test_net file: /home/abba/caffe/examples/simple/train.prototxt
I0812 10:54:05.557533 16297 net.cpp:287] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0812 10:54:05.557587 16297 net.cpp:42] Initializing net from parameters: 
name: "LogisticRegressionNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/abba/caffe/examples/simple/test_list.txt"
    batch_size: 5
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "data"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0812 10:54:05.557823 16297 net.cpp:67] Memory required for data: 0
I0812 10:54:05.557847 16297 layer_factory.hpp:74] Creating layer data
I0812 10:54:05.557862 16297 net.cpp:90] Creating Layer data
I0812 10:54:05.557873 16297 net.cpp:368] data -> data
I0812 10:54:05.557889 16297 net.cpp:368] data -> label
I0812 10:54:05.557904 16297 net.cpp:120] Setting up data
I0812 10:54:05.557914 16297 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/abba/caffe/examples/simple/test_list.txt
I0812 10:54:05.557935 16297 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
I0812 10:54:05.557945 16297 hdf5_data_layer.cpp:29] Loading HDF5 file: /home/abba/caffe/examples/simple/test.h5
I0812 10:54:05.558250 16297 hdf5_data_layer.cpp:68] Successully loaded 30 rows
I0812 10:54:05.558272 16297 net.cpp:127] Top shape: 5 2 (10)
I0812 10:54:05.558284 16297 net.cpp:127] Top shape: 5 1 (5)
I0812 10:54:05.558293 16297 net.cpp:133] Memory required for data: 60
I0812 10:54:05.558303 16297 layer_factory.hpp:74] Creating layer label_data_1_split
I0812 10:54:05.558318 16297 net.cpp:90] Creating Layer label_data_1_split
I0812 10:54:05.558328 16297 net.cpp:410] label_data_1_split <- label
I0812 10:54:05.558341 16297 net.cpp:368] label_data_1_split -> label_data_1_split_0
I0812 10:54:05.558357 16297 net.cpp:368] label_data_1_split -> label_data_1_split_1
I0812 10:54:05.558370 16297 net.cpp:120] Setting up label_data_1_split
I0812 10:54:05.558384 16297 net.cpp:127] Top shape: 5 1 (5)
I0812 10:54:05.558395 16297 net.cpp:127] Top shape: 5 1 (5)
I0812 10:54:05.558403 16297 net.cpp:133] Memory required for data: 100
I0812 10:54:05.558413 16297 layer_factory.hpp:74] Creating layer fc1
I0812 10:54:05.558428 16297 net.cpp:90] Creating Layer fc1
I0812 10:54:05.558437 16297 net.cpp:410] fc1 <- data
I0812 10:54:05.558452 16297 net.cpp:368] fc1 -> fc1
I0812 10:54:05.558467 16297 net.cpp:120] Setting up fc1
I0812 10:54:05.558492 16297 net.cpp:127] Top shape: 5 2 (10)
I0812 10:54:05.558502 16297 net.cpp:133] Memory required for data: 140
I0812 10:54:05.558518 16297 layer_factory.hpp:74] Creating layer fc1_fc1_0_split
I0812 10:54:05.558531 16297 net.cpp:90] Creating Layer fc1_fc1_0_split
I0812 10:54:05.558540 16297 net.cpp:410] fc1_fc1_0_split <- fc1
I0812 10:54:05.558553 16297 net.cpp:368] fc1_fc1_0_split -> fc1_fc1_0_split_0
I0812 10:54:05.558568 16297 net.cpp:368] fc1_fc1_0_split -> fc1_fc1_0_split_1
I0812 10:54:05.558580 16297 net.cpp:120] Setting up fc1_fc1_0_split
I0812 10:54:05.558593 16297 net.cpp:127] Top shape: 5 2 (10)
I0812 10:54:05.558604 16297 net.cpp:127] Top shape: 5 2 (10)
I0812 10:54:05.558612 16297 net.cpp:133] Memory required for data: 220
I0812 10:54:05.558621 16297 layer_factory.hpp:74] Creating layer loss
I0812 10:54:05.558634 16297 net.cpp:90] Creating Layer loss
I0812 10:54:05.558643 16297 net.cpp:410] loss <- fc1_fc1_0_split_0
I0812 10:54:05.558671 16297 net.cpp:410] loss <- label_data_1_split_0
I0812 10:54:05.558686 16297 net.cpp:368] loss -> loss
I0812 10:54:05.558698 16297 net.cpp:120] Setting up loss
I0812 10:54:05.558709 16297 layer_factory.hpp:74] Creating layer loss
I0812 10:54:05.558732 16297 net.cpp:127] Top shape: (1)
I0812 10:54:05.558743 16297 net.cpp:129]     with loss weight 1
I0812 10:54:05.558754 16297 net.cpp:133] Memory required for data: 224
I0812 10:54:05.558763 16297 layer_factory.hpp:74] Creating layer accuracy
I0812 10:54:05.558776 16297 net.cpp:90] Creating Layer accuracy
I0812 10:54:05.558786 16297 net.cpp:410] accuracy <- fc1_fc1_0_split_1
I0812 10:54:05.558799 16297 net.cpp:410] accuracy <- label_data_1_split_1
I0812 10:54:05.558811 16297 net.cpp:368] accuracy -> accuracy
I0812 10:54:05.558826 16297 net.cpp:120] Setting up accuracy
I0812 10:54:05.558840 16297 net.cpp:127] Top shape: (1)
I0812 10:54:05.558850 16297 net.cpp:133] Memory required for data: 228
I0812 10:54:05.558859 16297 net.cpp:194] accuracy does not need backward computation.
I0812 10:54:05.558869 16297 net.cpp:192] loss needs backward computation.
I0812 10:54:05.558879 16297 net.cpp:192] fc1_fc1_0_split needs backward computation.
I0812 10:54:05.558888 16297 net.cpp:192] fc1 needs backward computation.
I0812 10:54:05.558898 16297 net.cpp:194] label_data_1_split does not need backward computation.
I0812 10:54:05.558909 16297 net.cpp:194] data does not need backward computation.
I0812 10:54:05.558917 16297 net.cpp:235] This network produces output accuracy
I0812 10:54:05.558928 16297 net.cpp:235] This network produces output loss
I0812 10:54:05.558943 16297 net.cpp:482] Collecting Learning Rate and Weight Decay.
I0812 10:54:05.558954 16297 net.cpp:247] Network initialization done.
I0812 10:54:05.558962 16297 net.cpp:248] Memory required for data: 228
I0812 10:54:05.558987 16297 solver.cpp:42] Solver scaffolding done.
I0812 10:54:05.559005 16297 solver.cpp:250] Solving LogisticRegressionNet
I0812 10:54:05.559015 16297 solver.cpp:251] Learning Rate Policy: step
I0812 10:54:05.559025 16297 solver.cpp:294] Iteration 0, Testing net (#0)
I0812 10:54:05.559037 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.559046 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.559056 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.560312 16297 solver.cpp:343]     Test net output #0: accuracy = 0.566
I0812 10:54:05.560333 16297 solver.cpp:343]     Test net output #1: loss = 0.847679 (* 1 = 0.847679 loss)
I0812 10:54:05.560369 16297 solver.cpp:214] Iteration 0, loss = 0.696646
I0812 10:54:05.560386 16297 solver.cpp:229]     Train net output #0: loss = 0.696646 (* 1 = 0.696646 loss)
I0812 10:54:05.560400 16297 solver.cpp:486] Iteration 0, lr = 0.0001
I0812 10:54:05.565420 16297 solver.cpp:214] Iteration 500, loss = 0.608073
I0812 10:54:05.565459 16297 solver.cpp:229]     Train net output #0: loss = 0.608073 (* 1 = 0.608073 loss)
I0812 10:54:05.565480 16297 solver.cpp:486] Iteration 500, lr = 0.0001
I0812 10:54:05.570693 16297 solver.cpp:294] Iteration 1000, Testing net (#0)
I0812 10:54:05.570718 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.570726 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.570734 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.571976 16297 solver.cpp:343]     Test net output #0: accuracy = 0.506
I0812 10:54:05.572069 16297 solver.cpp:343]     Test net output #1: loss = 0.718035 (* 1 = 0.718035 loss)
I0812 10:54:05.572118 16297 solver.cpp:214] Iteration 1000, loss = 0.570141
I0812 10:54:05.572137 16297 solver.cpp:229]     Train net output #0: loss = 0.570141 (* 1 = 0.570141 loss)
I0812 10:54:05.572154 16297 solver.cpp:486] Iteration 1000, lr = 0.0001
I0812 10:54:05.577285 16297 solver.cpp:214] Iteration 1500, loss = 0.553539
I0812 10:54:05.577322 16297 solver.cpp:229]     Train net output #0: loss = 0.553539 (* 1 = 0.553539 loss)
I0812 10:54:05.577333 16297 solver.cpp:486] Iteration 1500, lr = 0.0001
I0812 10:54:05.582417 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.582517 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_2000.caffemodel
I0812 10:54:05.582705 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_2000.solverstate
I0812 10:54:05.582765 16297 solver.cpp:294] Iteration 2000, Testing net (#0)
I0812 10:54:05.582778 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.582788 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.582798 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.584035 16297 solver.cpp:343]     Test net output #0: accuracy = 0.53
I0812 10:54:05.584064 16297 solver.cpp:343]     Test net output #1: loss = 0.691421 (* 1 = 0.691421 loss)
I0812 10:54:05.584094 16297 solver.cpp:214] Iteration 2000, loss = 0.544207
I0812 10:54:05.584110 16297 solver.cpp:229]     Train net output #0: loss = 0.544207 (* 1 = 0.544207 loss)
I0812 10:54:05.584121 16297 solver.cpp:486] Iteration 2000, lr = 0.0001
I0812 10:54:05.589475 16297 solver.cpp:214] Iteration 2500, loss = 0.537174
I0812 10:54:05.589512 16297 solver.cpp:229]     Train net output #0: loss = 0.537174 (* 1 = 0.537174 loss)
I0812 10:54:05.589524 16297 solver.cpp:486] Iteration 2500, lr = 0.0001
I0812 10:54:05.594835 16297 solver.cpp:294] Iteration 3000, Testing net (#0)
I0812 10:54:05.594861 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.594871 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.594880 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.596101 16297 solver.cpp:343]     Test net output #0: accuracy = 0.5
I0812 10:54:05.596128 16297 solver.cpp:343]     Test net output #1: loss = 0.666258 (* 1 = 0.666258 loss)
I0812 10:54:05.596154 16297 solver.cpp:214] Iteration 3000, loss = 0.530874
I0812 10:54:05.596169 16297 solver.cpp:229]     Train net output #0: loss = 0.530874 (* 1 = 0.530874 loss)
I0812 10:54:05.596181 16297 solver.cpp:486] Iteration 3000, lr = 0.0001
I0812 10:54:05.601320 16297 solver.cpp:214] Iteration 3500, loss = 0.524856
I0812 10:54:05.601352 16297 solver.cpp:229]     Train net output #0: loss = 0.524856 (* 1 = 0.524856 loss)
I0812 10:54:05.601362 16297 solver.cpp:486] Iteration 3500, lr = 0.0001
I0812 10:54:05.606817 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.606868 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_4000.caffemodel
I0812 10:54:05.607041 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_4000.solverstate
I0812 10:54:05.607161 16297 solver.cpp:294] Iteration 4000, Testing net (#0)
I0812 10:54:05.607185 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.607194 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.607203 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.608430 16297 solver.cpp:343]     Test net output #0: accuracy = 0.54
I0812 10:54:05.608460 16297 solver.cpp:343]     Test net output #1: loss = 0.642362 (* 1 = 0.642362 loss)
I0812 10:54:05.608487 16297 solver.cpp:214] Iteration 4000, loss = 0.519008
I0812 10:54:05.608502 16297 solver.cpp:229]     Train net output #0: loss = 0.519008 (* 1 = 0.519008 loss)
I0812 10:54:05.608515 16297 solver.cpp:486] Iteration 4000, lr = 0.0001
I0812 10:54:05.613634 16297 solver.cpp:214] Iteration 4500, loss = 0.513308
I0812 10:54:05.613668 16297 solver.cpp:229]     Train net output #0: loss = 0.513308 (* 1 = 0.513308 loss)
I0812 10:54:05.613678 16297 solver.cpp:486] Iteration 4500, lr = 0.0001
I0812 10:54:05.618803 16297 solver.cpp:294] Iteration 5000, Testing net (#0)
I0812 10:54:05.618824 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.618831 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.618840 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.620064 16297 solver.cpp:343]     Test net output #0: accuracy = 0.594
I0812 10:54:05.620096 16297 solver.cpp:343]     Test net output #1: loss = 0.629667 (* 1 = 0.629667 loss)
I0812 10:54:05.620121 16297 solver.cpp:214] Iteration 5000, loss = 0.507759
I0812 10:54:05.620136 16297 solver.cpp:229]     Train net output #0: loss = 0.507759 (* 1 = 0.507759 loss)
I0812 10:54:05.620177 16297 solver.cpp:486] Iteration 5000, lr = 0.0001
I0812 10:54:05.625399 16297 solver.cpp:214] Iteration 5500, loss = 0.502361
I0812 10:54:05.625448 16297 solver.cpp:229]     Train net output #0: loss = 0.502361 (* 1 = 0.502361 loss)
I0812 10:54:05.625460 16297 solver.cpp:486] Iteration 5500, lr = 0.0001
I0812 10:54:05.630553 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.630597 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_6000.caffemodel
I0812 10:54:05.630767 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_6000.solverstate
I0812 10:54:05.630890 16297 solver.cpp:294] Iteration 6000, Testing net (#0)
I0812 10:54:05.630915 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.630925 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.630934 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.632154 16297 solver.cpp:343]     Test net output #0: accuracy = 0.632
I0812 10:54:05.632180 16297 solver.cpp:343]     Test net output #1: loss = 0.609169 (* 1 = 0.609169 loss)
I0812 10:54:05.632205 16297 solver.cpp:214] Iteration 6000, loss = 0.497117
I0812 10:54:05.632220 16297 solver.cpp:229]     Train net output #0: loss = 0.497117 (* 1 = 0.497117 loss)
I0812 10:54:05.632232 16297 solver.cpp:486] Iteration 6000, lr = 0.0001
I0812 10:54:05.637534 16297 solver.cpp:214] Iteration 6500, loss = 0.492023
I0812 10:54:05.637627 16297 solver.cpp:229]     Train net output #0: loss = 0.492023 (* 1 = 0.492023 loss)
I0812 10:54:05.637642 16297 solver.cpp:486] Iteration 6500, lr = 0.0001
I0812 10:54:05.642686 16297 solver.cpp:294] Iteration 7000, Testing net (#0)
I0812 10:54:05.642704 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.642712 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.642721 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.644017 16297 solver.cpp:343]     Test net output #0: accuracy = 0.74
I0812 10:54:05.644038 16297 solver.cpp:343]     Test net output #1: loss = 0.588748 (* 1 = 0.588748 loss)
I0812 10:54:05.644071 16297 solver.cpp:214] Iteration 7000, loss = 0.487076
I0812 10:54:05.644107 16297 solver.cpp:229]     Train net output #0: loss = 0.487076 (* 1 = 0.487076 loss)
I0812 10:54:05.644129 16297 solver.cpp:486] Iteration 7000, lr = 0.0001
I0812 10:54:05.649199 16297 solver.cpp:214] Iteration 7500, loss = 0.482273
I0812 10:54:05.649225 16297 solver.cpp:229]     Train net output #0: loss = 0.482273 (* 1 = 0.482273 loss)
I0812 10:54:05.649235 16297 solver.cpp:486] Iteration 7500, lr = 0.0001
I0812 10:54:05.654342 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.654463 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_8000.caffemodel
I0812 10:54:05.654832 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_8000.solverstate
I0812 10:54:05.655012 16297 solver.cpp:294] Iteration 8000, Testing net (#0)
I0812 10:54:05.655043 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.655052 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.655061 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.656350 16297 solver.cpp:343]     Test net output #0: accuracy = 0.728
I0812 10:54:05.656373 16297 solver.cpp:343]     Test net output #1: loss = 0.578492 (* 1 = 0.578492 loss)
I0812 10:54:05.656399 16297 solver.cpp:214] Iteration 8000, loss = 0.477607
I0812 10:54:05.656414 16297 solver.cpp:229]     Train net output #0: loss = 0.477607 (* 1 = 0.477607 loss)
I0812 10:54:05.656425 16297 solver.cpp:486] Iteration 8000, lr = 0.0001
I0812 10:54:05.661483 16297 solver.cpp:214] Iteration 8500, loss = 0.473075
I0812 10:54:05.661507 16297 solver.cpp:229]     Train net output #0: loss = 0.473075 (* 1 = 0.473075 loss)
I0812 10:54:05.661517 16297 solver.cpp:486] Iteration 8500, lr = 0.0001
I0812 10:54:05.666512 16297 solver.cpp:294] Iteration 9000, Testing net (#0)
I0812 10:54:05.666527 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.666568 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.666576 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.667971 16297 solver.cpp:343]     Test net output #0: accuracy = 0.798
I0812 10:54:05.667995 16297 solver.cpp:343]     Test net output #1: loss = 0.561646 (* 1 = 0.561646 loss)
I0812 10:54:05.668020 16297 solver.cpp:214] Iteration 9000, loss = 0.46867
I0812 10:54:05.668035 16297 solver.cpp:229]     Train net output #0: loss = 0.46867 (* 1 = 0.46867 loss)
I0812 10:54:05.668045 16297 solver.cpp:486] Iteration 9000, lr = 0.0001
I0812 10:54:05.673157 16297 solver.cpp:214] Iteration 9500, loss = 0.464388
I0812 10:54:05.673189 16297 solver.cpp:229]     Train net output #0: loss = 0.464388 (* 1 = 0.464388 loss)
I0812 10:54:05.673199 16297 solver.cpp:486] Iteration 9500, lr = 0.0001
I0812 10:54:05.678202 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.678239 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_10000.caffemodel
I0812 10:54:05.678443 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_10000.solverstate
I0812 10:54:05.678582 16297 solver.cpp:294] Iteration 10000, Testing net (#0)
I0812 10:54:05.678628 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.678637 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.678645 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.679889 16297 solver.cpp:343]     Test net output #0: accuracy = 0.806
I0812 10:54:05.679910 16297 solver.cpp:343]     Test net output #1: loss = 0.544223 (* 1 = 0.544223 loss)
I0812 10:54:05.679934 16297 solver.cpp:214] Iteration 10000, loss = 0.460225
I0812 10:54:05.679949 16297 solver.cpp:229]     Train net output #0: loss = 0.460225 (* 1 = 0.460225 loss)
I0812 10:54:05.679960 16297 solver.cpp:486] Iteration 10000, lr = 0.0001
I0812 10:54:05.685240 16297 solver.cpp:214] Iteration 10500, loss = 0.456174
I0812 10:54:05.685278 16297 solver.cpp:229]     Train net output #0: loss = 0.456174 (* 1 = 0.456174 loss)
I0812 10:54:05.685291 16297 solver.cpp:486] Iteration 10500, lr = 0.0001
I0812 10:54:05.690331 16297 solver.cpp:294] Iteration 11000, Testing net (#0)
I0812 10:54:05.690353 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.690363 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.690372 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.691601 16297 solver.cpp:343]     Test net output #0: accuracy = 0.796
I0812 10:54:05.691622 16297 solver.cpp:343]     Test net output #1: loss = 0.535913 (* 1 = 0.535913 loss)
I0812 10:54:05.691655 16297 solver.cpp:214] Iteration 11000, loss = 0.452233
I0812 10:54:05.691690 16297 solver.cpp:229]     Train net output #0: loss = 0.452233 (* 1 = 0.452233 loss)
I0812 10:54:05.691701 16297 solver.cpp:486] Iteration 11000, lr = 0.0001
I0812 10:54:05.696858 16297 solver.cpp:214] Iteration 11500, loss = 0.448396
I0812 10:54:05.696882 16297 solver.cpp:229]     Train net output #0: loss = 0.448396 (* 1 = 0.448396 loss)
I0812 10:54:05.696893 16297 solver.cpp:486] Iteration 11500, lr = 0.0001
I0812 10:54:05.701894 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.701933 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_12000.caffemodel
I0812 10:54:05.702137 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_12000.solverstate
I0812 10:54:05.702255 16297 solver.cpp:294] Iteration 12000, Testing net (#0)
I0812 10:54:05.702288 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.702298 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.702307 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.703608 16297 solver.cpp:343]     Test net output #0: accuracy = 0.832
I0812 10:54:05.703630 16297 solver.cpp:343]     Test net output #1: loss = 0.522002 (* 1 = 0.522002 loss)
I0812 10:54:05.703655 16297 solver.cpp:214] Iteration 12000, loss = 0.444659
I0812 10:54:05.703670 16297 solver.cpp:229]     Train net output #0: loss = 0.444659 (* 1 = 0.444659 loss)
I0812 10:54:05.703699 16297 solver.cpp:486] Iteration 12000, lr = 0.0001
I0812 10:54:05.708775 16297 solver.cpp:214] Iteration 12500, loss = 0.441019
I0812 10:54:05.708814 16297 solver.cpp:229]     Train net output #0: loss = 0.441019 (* 1 = 0.441019 loss)
I0812 10:54:05.708825 16297 solver.cpp:486] Iteration 12500, lr = 0.0001
I0812 10:54:05.713856 16297 solver.cpp:294] Iteration 13000, Testing net (#0)
I0812 10:54:05.713872 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.713881 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.713891 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.715136 16297 solver.cpp:343]     Test net output #0: accuracy = 0.838
I0812 10:54:05.715157 16297 solver.cpp:343]     Test net output #1: loss = 0.506993 (* 1 = 0.506993 loss)
I0812 10:54:05.715179 16297 solver.cpp:214] Iteration 13000, loss = 0.437472
I0812 10:54:05.715194 16297 solver.cpp:229]     Train net output #0: loss = 0.437472 (* 1 = 0.437472 loss)
I0812 10:54:05.715214 16297 solver.cpp:486] Iteration 13000, lr = 0.0001
I0812 10:54:05.720260 16297 solver.cpp:214] Iteration 13500, loss = 0.434014
I0812 10:54:05.720289 16297 solver.cpp:229]     Train net output #0: loss = 0.434014 (* 1 = 0.434014 loss)
I0812 10:54:05.720299 16297 solver.cpp:486] Iteration 13500, lr = 0.0001
I0812 10:54:05.725320 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.725361 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_14000.caffemodel
I0812 10:54:05.725554 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_14000.solverstate
I0812 10:54:05.725704 16297 solver.cpp:294] Iteration 14000, Testing net (#0)
I0812 10:54:05.725739 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.725749 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.725759 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.727007 16297 solver.cpp:343]     Test net output #0: accuracy = 0.864
I0812 10:54:05.727041 16297 solver.cpp:343]     Test net output #1: loss = 0.500185 (* 1 = 0.500185 loss)
I0812 10:54:05.727076 16297 solver.cpp:214] Iteration 14000, loss = 0.430641
I0812 10:54:05.727090 16297 solver.cpp:229]     Train net output #0: loss = 0.430641 (* 1 = 0.430641 loss)
I0812 10:54:05.727100 16297 solver.cpp:486] Iteration 14000, lr = 0.0001
I0812 10:54:05.732167 16297 solver.cpp:214] Iteration 14500, loss = 0.427352
I0812 10:54:05.732192 16297 solver.cpp:229]     Train net output #0: loss = 0.427352 (* 1 = 0.427352 loss)
I0812 10:54:05.732213 16297 solver.cpp:486] Iteration 14500, lr = 0.0001
I0812 10:54:05.737368 16297 solver.cpp:294] Iteration 15000, Testing net (#0)
I0812 10:54:05.737450 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.737462 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.737473 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.738857 16297 solver.cpp:343]     Test net output #0: accuracy = 0.866
I0812 10:54:05.738883 16297 solver.cpp:343]     Test net output #1: loss = 0.488618 (* 1 = 0.488618 loss)
I0812 10:54:05.738917 16297 solver.cpp:214] Iteration 15000, loss = 0.424141
I0812 10:54:05.738932 16297 solver.cpp:229]     Train net output #0: loss = 0.424141 (* 1 = 0.424141 loss)
I0812 10:54:05.738944 16297 solver.cpp:486] Iteration 15000, lr = 0.0001
I0812 10:54:05.744029 16297 solver.cpp:214] Iteration 15500, loss = 0.421007
I0812 10:54:05.744055 16297 solver.cpp:229]     Train net output #0: loss = 0.421007 (* 1 = 0.421007 loss)
I0812 10:54:05.744065 16297 solver.cpp:486] Iteration 15500, lr = 0.0001
I0812 10:54:05.749157 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.749218 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_16000.caffemodel
I0812 10:54:05.749457 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_16000.solverstate
I0812 10:54:05.749598 16297 solver.cpp:294] Iteration 16000, Testing net (#0)
I0812 10:54:05.749622 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.749632 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.749655 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.750872 16297 solver.cpp:343]     Test net output #0: accuracy = 0.87
I0812 10:54:05.750897 16297 solver.cpp:343]     Test net output #1: loss = 0.475554 (* 1 = 0.475554 loss)
I0812 10:54:05.750923 16297 solver.cpp:214] Iteration 16000, loss = 0.417946
I0812 10:54:05.750938 16297 solver.cpp:229]     Train net output #0: loss = 0.417946 (* 1 = 0.417946 loss)
I0812 10:54:05.750948 16297 solver.cpp:486] Iteration 16000, lr = 0.0001
I0812 10:54:05.755998 16297 solver.cpp:214] Iteration 16500, loss = 0.414957
I0812 10:54:05.756032 16297 solver.cpp:229]     Train net output #0: loss = 0.414957 (* 1 = 0.414957 loss)
I0812 10:54:05.756042 16297 solver.cpp:486] Iteration 16500, lr = 0.0001
I0812 10:54:05.761164 16297 solver.cpp:294] Iteration 17000, Testing net (#0)
I0812 10:54:05.761179 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.761188 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.761195 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.762421 16297 solver.cpp:343]     Test net output #0: accuracy = 0.898
I0812 10:54:05.762454 16297 solver.cpp:343]     Test net output #1: loss = 0.46991 (* 1 = 0.46991 loss)
I0812 10:54:05.762478 16297 solver.cpp:214] Iteration 17000, loss = 0.412035
I0812 10:54:05.762514 16297 solver.cpp:229]     Train net output #0: loss = 0.412035 (* 1 = 0.412035 loss)
I0812 10:54:05.762537 16297 solver.cpp:486] Iteration 17000, lr = 0.0001
I0812 10:54:05.767608 16297 solver.cpp:214] Iteration 17500, loss = 0.40918
I0812 10:54:05.767637 16297 solver.cpp:229]     Train net output #0: loss = 0.40918 (* 1 = 0.40918 loss)
I0812 10:54:05.767647 16297 solver.cpp:486] Iteration 17500, lr = 0.0001
I0812 10:54:05.772696 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.772740 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_18000.caffemodel
I0812 10:54:05.772912 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_18000.solverstate
I0812 10:54:05.773030 16297 solver.cpp:294] Iteration 18000, Testing net (#0)
I0812 10:54:05.773053 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.773062 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.773072 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.774330 16297 solver.cpp:343]     Test net output #0: accuracy = 0.934
I0812 10:54:05.774353 16297 solver.cpp:343]     Test net output #1: loss = 0.460229 (* 1 = 0.460229 loss)
I0812 10:54:05.774379 16297 solver.cpp:214] Iteration 18000, loss = 0.406387
I0812 10:54:05.774392 16297 solver.cpp:229]     Train net output #0: loss = 0.406387 (* 1 = 0.406387 loss)
I0812 10:54:05.774404 16297 solver.cpp:486] Iteration 18000, lr = 0.0001
I0812 10:54:05.779428 16297 solver.cpp:214] Iteration 18500, loss = 0.403656
I0812 10:54:05.779449 16297 solver.cpp:229]     Train net output #0: loss = 0.403656 (* 1 = 0.403656 loss)
I0812 10:54:05.779471 16297 solver.cpp:486] Iteration 18500, lr = 0.0001
I0812 10:54:05.784600 16297 solver.cpp:294] Iteration 19000, Testing net (#0)
I0812 10:54:05.784620 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.784627 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.784636 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.785868 16297 solver.cpp:343]     Test net output #0: accuracy = 0.934
I0812 10:54:05.785903 16297 solver.cpp:343]     Test net output #1: loss = 0.448745 (* 1 = 0.448745 loss)
I0812 10:54:05.785928 16297 solver.cpp:214] Iteration 19000, loss = 0.400984
I0812 10:54:05.785953 16297 solver.cpp:229]     Train net output #0: loss = 0.400984 (* 1 = 0.400984 loss)
I0812 10:54:05.785964 16297 solver.cpp:486] Iteration 19000, lr = 0.0001
I0812 10:54:05.791137 16297 solver.cpp:214] Iteration 19500, loss = 0.398369
I0812 10:54:05.791169 16297 solver.cpp:229]     Train net output #0: loss = 0.398369 (* 1 = 0.398369 loss)
I0812 10:54:05.791179 16297 solver.cpp:486] Iteration 19500, lr = 0.0001
I0812 10:54:05.796100 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.796172 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_20000.caffemodel
I0812 10:54:05.796383 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_20000.solverstate
I0812 10:54:05.796521 16297 solver.cpp:294] Iteration 20000, Testing net (#0)
I0812 10:54:05.796545 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.796555 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.796563 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.797906 16297 solver.cpp:343]     Test net output #0: accuracy = 0.966
I0812 10:54:05.797930 16297 solver.cpp:343]     Test net output #1: loss = 0.444013 (* 1 = 0.444013 loss)
I0812 10:54:05.797953 16297 solver.cpp:214] Iteration 20000, loss = 0.395809
I0812 10:54:05.797968 16297 solver.cpp:229]     Train net output #0: loss = 0.395809 (* 1 = 0.395809 loss)
I0812 10:54:05.797978 16297 solver.cpp:486] Iteration 20000, lr = 0.0001
I0812 10:54:05.802997 16297 solver.cpp:214] Iteration 20500, loss = 0.393301
I0812 10:54:05.803028 16297 solver.cpp:229]     Train net output #0: loss = 0.393301 (* 1 = 0.393301 loss)
I0812 10:54:05.803040 16297 solver.cpp:486] Iteration 20500, lr = 0.0001
I0812 10:54:05.808125 16297 solver.cpp:294] Iteration 21000, Testing net (#0)
I0812 10:54:05.808147 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.808154 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.808163 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.809409 16297 solver.cpp:343]     Test net output #0: accuracy = 0.968
I0812 10:54:05.809449 16297 solver.cpp:343]     Test net output #1: loss = 0.435861 (* 1 = 0.435861 loss)
I0812 10:54:05.809475 16297 solver.cpp:214] Iteration 21000, loss = 0.390845
I0812 10:54:05.809514 16297 solver.cpp:229]     Train net output #0: loss = 0.390845 (* 1 = 0.390845 loss)
I0812 10:54:05.809525 16297 solver.cpp:486] Iteration 21000, lr = 0.0001
I0812 10:54:05.814584 16297 solver.cpp:214] Iteration 21500, loss = 0.388439
I0812 10:54:05.814607 16297 solver.cpp:229]     Train net output #0: loss = 0.388439 (* 1 = 0.388439 loss)
I0812 10:54:05.814617 16297 solver.cpp:486] Iteration 21500, lr = 0.0001
I0812 10:54:05.819672 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.819711 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_22000.caffemodel
I0812 10:54:05.819888 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_22000.solverstate
I0812 10:54:05.820029 16297 solver.cpp:294] Iteration 22000, Testing net (#0)
I0812 10:54:05.820053 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.820075 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.820085 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.821463 16297 solver.cpp:343]     Test net output #0: accuracy = 0.966
I0812 10:54:05.821498 16297 solver.cpp:343]     Test net output #1: loss = 0.425671 (* 1 = 0.425671 loss)
I0812 10:54:05.821528 16297 solver.cpp:214] Iteration 22000, loss = 0.38608
I0812 10:54:05.821544 16297 solver.cpp:229]     Train net output #0: loss = 0.38608 (* 1 = 0.38608 loss)
I0812 10:54:05.821569 16297 solver.cpp:486] Iteration 22000, lr = 0.0001
I0812 10:54:05.826624 16297 solver.cpp:214] Iteration 22500, loss = 0.383768
I0812 10:54:05.826648 16297 solver.cpp:229]     Train net output #0: loss = 0.383768 (* 1 = 0.383768 loss)
I0812 10:54:05.826658 16297 solver.cpp:486] Iteration 22500, lr = 0.0001
I0812 10:54:05.831682 16297 solver.cpp:294] Iteration 23000, Testing net (#0)
I0812 10:54:05.831698 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.831706 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.831713 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.832937 16297 solver.cpp:343]     Test net output #0: accuracy = 0.966
I0812 10:54:05.832957 16297 solver.cpp:343]     Test net output #1: loss = 0.421658 (* 1 = 0.421658 loss)
I0812 10:54:05.832993 16297 solver.cpp:214] Iteration 23000, loss = 0.381501
I0812 10:54:05.833032 16297 solver.cpp:229]     Train net output #0: loss = 0.381501 (* 1 = 0.381501 loss)
I0812 10:54:05.833044 16297 solver.cpp:486] Iteration 23000, lr = 0.0001
I0812 10:54:05.838388 16297 solver.cpp:214] Iteration 23500, loss = 0.379277
I0812 10:54:05.838434 16297 solver.cpp:229]     Train net output #0: loss = 0.379277 (* 1 = 0.379277 loss)
I0812 10:54:05.838446 16297 solver.cpp:486] Iteration 23500, lr = 0.0001
I0812 10:54:05.843437 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.843477 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_24000.caffemodel
I0812 10:54:05.843647 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_24000.solverstate
I0812 10:54:05.843765 16297 solver.cpp:294] Iteration 24000, Testing net (#0)
I0812 10:54:05.843791 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.843799 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.843809 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.845017 16297 solver.cpp:343]     Test net output #0: accuracy = 0.968
I0812 10:54:05.845038 16297 solver.cpp:343]     Test net output #1: loss = 0.414758 (* 1 = 0.414758 loss)
I0812 10:54:05.845063 16297 solver.cpp:214] Iteration 24000, loss = 0.377094
I0812 10:54:05.845078 16297 solver.cpp:229]     Train net output #0: loss = 0.377094 (* 1 = 0.377094 loss)
I0812 10:54:05.845089 16297 solver.cpp:486] Iteration 24000, lr = 0.0001
I0812 10:54:05.850150 16297 solver.cpp:214] Iteration 24500, loss = 0.374953
I0812 10:54:05.850173 16297 solver.cpp:229]     Train net output #0: loss = 0.374953 (* 1 = 0.374953 loss)
I0812 10:54:05.850224 16297 solver.cpp:486] Iteration 24500, lr = 0.0001
I0812 10:54:05.855399 16297 solver.cpp:294] Iteration 25000, Testing net (#0)
I0812 10:54:05.855427 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.855434 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.855443 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.856653 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.856678 16297 solver.cpp:343]     Test net output #1: loss = 0.405634 (* 1 = 0.405634 loss)
I0812 10:54:05.856701 16297 solver.cpp:214] Iteration 25000, loss = 0.37285
I0812 10:54:05.856715 16297 solver.cpp:229]     Train net output #0: loss = 0.37285 (* 1 = 0.37285 loss)
I0812 10:54:05.856725 16297 solver.cpp:486] Iteration 25000, lr = 0.0001
I0812 10:54:05.861868 16297 solver.cpp:214] Iteration 25500, loss = 0.370786
I0812 10:54:05.861893 16297 solver.cpp:229]     Train net output #0: loss = 0.370786 (* 1 = 0.370786 loss)
I0812 10:54:05.861903 16297 solver.cpp:486] Iteration 25500, lr = 0.0001
I0812 10:54:05.866852 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.866888 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_26000.caffemodel
I0812 10:54:05.867049 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_26000.solverstate
I0812 10:54:05.867198 16297 solver.cpp:294] Iteration 26000, Testing net (#0)
I0812 10:54:05.867211 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.867230 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.867239 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.868592 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.868615 16297 solver.cpp:343]     Test net output #1: loss = 0.402199 (* 1 = 0.402199 loss)
I0812 10:54:05.868643 16297 solver.cpp:214] Iteration 26000, loss = 0.368759
I0812 10:54:05.868659 16297 solver.cpp:229]     Train net output #0: loss = 0.368759 (* 1 = 0.368759 loss)
I0812 10:54:05.868669 16297 solver.cpp:486] Iteration 26000, lr = 0.0001
I0812 10:54:05.873754 16297 solver.cpp:214] Iteration 26500, loss = 0.366767
I0812 10:54:05.873786 16297 solver.cpp:229]     Train net output #0: loss = 0.366767 (* 1 = 0.366767 loss)
I0812 10:54:05.873797 16297 solver.cpp:486] Iteration 26500, lr = 0.0001
I0812 10:54:05.878866 16297 solver.cpp:294] Iteration 27000, Testing net (#0)
I0812 10:54:05.878908 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.878917 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.878926 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.880136 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.880158 16297 solver.cpp:343]     Test net output #1: loss = 0.39633 (* 1 = 0.39633 loss)
I0812 10:54:05.880182 16297 solver.cpp:214] Iteration 27000, loss = 0.36481
I0812 10:54:05.880197 16297 solver.cpp:229]     Train net output #0: loss = 0.36481 (* 1 = 0.36481 loss)
I0812 10:54:05.880206 16297 solver.cpp:486] Iteration 27000, lr = 0.0001
I0812 10:54:05.885257 16297 solver.cpp:214] Iteration 27500, loss = 0.362887
I0812 10:54:05.885287 16297 solver.cpp:229]     Train net output #0: loss = 0.362887 (* 1 = 0.362887 loss)
I0812 10:54:05.885296 16297 solver.cpp:486] Iteration 27500, lr = 0.0001
I0812 10:54:05.890377 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.890419 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_28000.caffemodel
I0812 10:54:05.890588 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_28000.solverstate
I0812 10:54:05.890707 16297 solver.cpp:294] Iteration 28000, Testing net (#0)
I0812 10:54:05.890730 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.890740 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.890749 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.892065 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.892086 16297 solver.cpp:343]     Test net output #1: loss = 0.388093 (* 1 = 0.388093 loss)
I0812 10:54:05.892133 16297 solver.cpp:214] Iteration 28000, loss = 0.360996
I0812 10:54:05.892148 16297 solver.cpp:229]     Train net output #0: loss = 0.360996 (* 1 = 0.360996 loss)
I0812 10:54:05.892159 16297 solver.cpp:486] Iteration 28000, lr = 0.0001
I0812 10:54:05.897271 16297 solver.cpp:214] Iteration 28500, loss = 0.359138
I0812 10:54:05.897297 16297 solver.cpp:229]     Train net output #0: loss = 0.359138 (* 1 = 0.359138 loss)
I0812 10:54:05.897307 16297 solver.cpp:486] Iteration 28500, lr = 0.0001
I0812 10:54:05.902436 16297 solver.cpp:294] Iteration 29000, Testing net (#0)
I0812 10:54:05.902454 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.902462 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.902472 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.903731 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.903756 16297 solver.cpp:343]     Test net output #1: loss = 0.385124 (* 1 = 0.385124 loss)
I0812 10:54:05.903782 16297 solver.cpp:214] Iteration 29000, loss = 0.357309
I0812 10:54:05.903820 16297 solver.cpp:229]     Train net output #0: loss = 0.357309 (* 1 = 0.357309 loss)
I0812 10:54:05.903831 16297 solver.cpp:486] Iteration 29000, lr = 0.0001
I0812 10:54:05.908869 16297 solver.cpp:214] Iteration 29500, loss = 0.355511
I0812 10:54:05.908900 16297 solver.cpp:229]     Train net output #0: loss = 0.355511 (* 1 = 0.355511 loss)
I0812 10:54:05.908910 16297 solver.cpp:486] Iteration 29500, lr = 0.0001
I0812 10:54:05.913853 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.913913 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_30000.caffemodel
I0812 10:54:05.914180 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_30000.solverstate
I0812 10:54:05.914337 16297 solver.cpp:294] Iteration 30000, Testing net (#0)
I0812 10:54:05.914361 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.914394 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.914403 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.915760 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.915781 16297 solver.cpp:343]     Test net output #1: loss = 0.380113 (* 1 = 0.380113 loss)
I0812 10:54:05.915828 16297 solver.cpp:214] Iteration 30000, loss = 0.353742
I0812 10:54:05.915866 16297 solver.cpp:229]     Train net output #0: loss = 0.353742 (* 1 = 0.353742 loss)
I0812 10:54:05.915906 16297 solver.cpp:486] Iteration 30000, lr = 0.0001
I0812 10:54:05.920939 16297 solver.cpp:214] Iteration 30500, loss = 0.352001
I0812 10:54:05.920979 16297 solver.cpp:229]     Train net output #0: loss = 0.352001 (* 1 = 0.352001 loss)
I0812 10:54:05.920990 16297 solver.cpp:486] Iteration 30500, lr = 0.0001
I0812 10:54:05.926019 16297 solver.cpp:294] Iteration 31000, Testing net (#0)
I0812 10:54:05.926038 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.926059 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.926069 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.927356 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.927376 16297 solver.cpp:343]     Test net output #1: loss = 0.372619 (* 1 = 0.372619 loss)
I0812 10:54:05.927424 16297 solver.cpp:214] Iteration 31000, loss = 0.350287
I0812 10:54:05.927438 16297 solver.cpp:229]     Train net output #0: loss = 0.350287 (* 1 = 0.350287 loss)
I0812 10:54:05.927460 16297 solver.cpp:486] Iteration 31000, lr = 0.0001
I0812 10:54:05.932476 16297 solver.cpp:214] Iteration 31500, loss = 0.3486
I0812 10:54:05.932498 16297 solver.cpp:229]     Train net output #0: loss = 0.3486 (* 1 = 0.3486 loss)
I0812 10:54:05.932508 16297 solver.cpp:486] Iteration 31500, lr = 0.0001
I0812 10:54:05.937574 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.937646 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_32000.caffemodel
I0812 10:54:05.937906 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_32000.solverstate
I0812 10:54:05.938060 16297 solver.cpp:294] Iteration 32000, Testing net (#0)
I0812 10:54:05.938084 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.938094 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.938105 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.939349 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.939384 16297 solver.cpp:343]     Test net output #1: loss = 0.370033 (* 1 = 0.370033 loss)
I0812 10:54:05.939421 16297 solver.cpp:214] Iteration 32000, loss = 0.346939
I0812 10:54:05.939448 16297 solver.cpp:229]     Train net output #0: loss = 0.346939 (* 1 = 0.346939 loss)
I0812 10:54:05.939460 16297 solver.cpp:486] Iteration 32000, lr = 0.0001
I0812 10:54:05.944525 16297 solver.cpp:214] Iteration 32500, loss = 0.345303
I0812 10:54:05.944550 16297 solver.cpp:229]     Train net output #0: loss = 0.345303 (* 1 = 0.345303 loss)
I0812 10:54:05.944560 16297 solver.cpp:486] Iteration 32500, lr = 0.0001
I0812 10:54:05.949604 16297 solver.cpp:294] Iteration 33000, Testing net (#0)
I0812 10:54:05.949618 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.949625 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.949633 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.951020 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.951055 16297 solver.cpp:343]     Test net output #1: loss = 0.36574 (* 1 = 0.36574 loss)
I0812 10:54:05.951081 16297 solver.cpp:214] Iteration 33000, loss = 0.343692
I0812 10:54:05.951097 16297 solver.cpp:229]     Train net output #0: loss = 0.343692 (* 1 = 0.343692 loss)
I0812 10:54:05.951107 16297 solver.cpp:486] Iteration 33000, lr = 0.0001
I0812 10:54:05.956202 16297 solver.cpp:214] Iteration 33500, loss = 0.342104
I0812 10:54:05.956235 16297 solver.cpp:229]     Train net output #0: loss = 0.342104 (* 1 = 0.342104 loss)
I0812 10:54:05.956245 16297 solver.cpp:486] Iteration 33500, lr = 0.0001
I0812 10:54:05.961344 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.961381 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_34000.caffemodel
I0812 10:54:05.961565 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_34000.solverstate
I0812 10:54:05.961729 16297 solver.cpp:294] Iteration 34000, Testing net (#0)
I0812 10:54:05.961766 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.961824 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.961834 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.963066 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.963089 16297 solver.cpp:343]     Test net output #1: loss = 0.358874 (* 1 = 0.358874 loss)
I0812 10:54:05.963115 16297 solver.cpp:214] Iteration 34000, loss = 0.34054
I0812 10:54:05.963130 16297 solver.cpp:229]     Train net output #0: loss = 0.34054 (* 1 = 0.34054 loss)
I0812 10:54:05.963141 16297 solver.cpp:486] Iteration 34000, lr = 0.0001
I0812 10:54:05.968158 16297 solver.cpp:214] Iteration 34500, loss = 0.338999
I0812 10:54:05.968189 16297 solver.cpp:229]     Train net output #0: loss = 0.338999 (* 1 = 0.338999 loss)
I0812 10:54:05.968200 16297 solver.cpp:486] Iteration 34500, lr = 0.0001
I0812 10:54:05.973206 16297 solver.cpp:294] Iteration 35000, Testing net (#0)
I0812 10:54:05.973227 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.973235 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.973244 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.974460 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.974485 16297 solver.cpp:343]     Test net output #1: loss = 0.356604 (* 1 = 0.356604 loss)
I0812 10:54:05.974510 16297 solver.cpp:214] Iteration 35000, loss = 0.337479
I0812 10:54:05.974525 16297 solver.cpp:229]     Train net output #0: loss = 0.337479 (* 1 = 0.337479 loss)
I0812 10:54:05.974535 16297 solver.cpp:486] Iteration 35000, lr = 0.0001
I0812 10:54:05.979534 16297 solver.cpp:214] Iteration 35500, loss = 0.335981
I0812 10:54:05.979579 16297 solver.cpp:229]     Train net output #0: loss = 0.335981 (* 1 = 0.335981 loss)
I0812 10:54:05.979601 16297 solver.cpp:486] Iteration 35500, lr = 0.0001
I0812 10:54:05.984851 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:05.984894 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_36000.caffemodel
I0812 10:54:05.985060 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_36000.solverstate
I0812 10:54:05.985178 16297 solver.cpp:294] Iteration 36000, Testing net (#0)
I0812 10:54:05.985203 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.985213 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.985222 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.986469 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.986491 16297 solver.cpp:343]     Test net output #1: loss = 0.352914 (* 1 = 0.352914 loss)
I0812 10:54:05.986516 16297 solver.cpp:214] Iteration 36000, loss = 0.334504
I0812 10:54:05.986532 16297 solver.cpp:229]     Train net output #0: loss = 0.334504 (* 1 = 0.334504 loss)
I0812 10:54:05.986543 16297 solver.cpp:486] Iteration 36000, lr = 0.0001
I0812 10:54:05.991627 16297 solver.cpp:214] Iteration 36500, loss = 0.333047
I0812 10:54:05.991670 16297 solver.cpp:229]     Train net output #0: loss = 0.333047 (* 1 = 0.333047 loss)
I0812 10:54:05.991683 16297 solver.cpp:486] Iteration 36500, lr = 0.0001
I0812 10:54:05.996773 16297 solver.cpp:294] Iteration 37000, Testing net (#0)
I0812 10:54:05.996789 16297 net.cpp:671] Copying source layer data
I0812 10:54:05.996798 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:05.996806 16297 net.cpp:671] Copying source layer loss
I0812 10:54:05.998018 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:05.998041 16297 solver.cpp:343]     Test net output #1: loss = 0.346583 (* 1 = 0.346583 loss)
I0812 10:54:05.998066 16297 solver.cpp:214] Iteration 37000, loss = 0.33161
I0812 10:54:05.998080 16297 solver.cpp:229]     Train net output #0: loss = 0.33161 (* 1 = 0.33161 loss)
I0812 10:54:05.998091 16297 solver.cpp:486] Iteration 37000, lr = 0.0001
I0812 10:54:06.003118 16297 solver.cpp:214] Iteration 37500, loss = 0.330193
I0812 10:54:06.003146 16297 solver.cpp:229]     Train net output #0: loss = 0.330193 (* 1 = 0.330193 loss)
I0812 10:54:06.003156 16297 solver.cpp:486] Iteration 37500, lr = 0.0001
I0812 10:54:06.008262 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.008335 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_38000.caffemodel
I0812 10:54:06.008496 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_38000.solverstate
I0812 10:54:06.008615 16297 solver.cpp:294] Iteration 38000, Testing net (#0)
I0812 10:54:06.008640 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.008648 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.008658 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.009930 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.009953 16297 solver.cpp:343]     Test net output #1: loss = 0.344578 (* 1 = 0.344578 loss)
I0812 10:54:06.009976 16297 solver.cpp:214] Iteration 38000, loss = 0.328794
I0812 10:54:06.009991 16297 solver.cpp:229]     Train net output #0: loss = 0.328794 (* 1 = 0.328794 loss)
I0812 10:54:06.010017 16297 solver.cpp:486] Iteration 38000, lr = 0.0001
I0812 10:54:06.015084 16297 solver.cpp:214] Iteration 38500, loss = 0.327414
I0812 10:54:06.015110 16297 solver.cpp:229]     Train net output #0: loss = 0.327414 (* 1 = 0.327414 loss)
I0812 10:54:06.015120 16297 solver.cpp:486] Iteration 38500, lr = 0.0001
I0812 10:54:06.020201 16297 solver.cpp:294] Iteration 39000, Testing net (#0)
I0812 10:54:06.020220 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.020228 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.020236 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.021474 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.021510 16297 solver.cpp:343]     Test net output #1: loss = 0.341402 (* 1 = 0.341402 loss)
I0812 10:54:06.021541 16297 solver.cpp:214] Iteration 39000, loss = 0.326052
I0812 10:54:06.021558 16297 solver.cpp:229]     Train net output #0: loss = 0.326052 (* 1 = 0.326052 loss)
I0812 10:54:06.021570 16297 solver.cpp:486] Iteration 39000, lr = 0.0001
I0812 10:54:06.026672 16297 solver.cpp:214] Iteration 39500, loss = 0.324708
I0812 10:54:06.026707 16297 solver.cpp:229]     Train net output #0: loss = 0.324708 (* 1 = 0.324708 loss)
I0812 10:54:06.026718 16297 solver.cpp:486] Iteration 39500, lr = 0.0001
I0812 10:54:06.031898 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.031954 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_40000.caffemodel
I0812 10:54:06.032133 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_40000.solverstate
I0812 10:54:06.032269 16297 solver.cpp:294] Iteration 40000, Testing net (#0)
I0812 10:54:06.032297 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.032306 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.032316 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.033550 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.033588 16297 solver.cpp:343]     Test net output #1: loss = 0.335528 (* 1 = 0.335528 loss)
I0812 10:54:06.033623 16297 solver.cpp:214] Iteration 40000, loss = 0.323381
I0812 10:54:06.033639 16297 solver.cpp:229]     Train net output #0: loss = 0.323381 (* 1 = 0.323381 loss)
I0812 10:54:06.033653 16297 solver.cpp:486] Iteration 40000, lr = 0.0001
I0812 10:54:06.038760 16297 solver.cpp:214] Iteration 40500, loss = 0.32207
I0812 10:54:06.038817 16297 solver.cpp:229]     Train net output #0: loss = 0.32207 (* 1 = 0.32207 loss)
I0812 10:54:06.038828 16297 solver.cpp:486] Iteration 40500, lr = 0.0001
I0812 10:54:06.044028 16297 solver.cpp:294] Iteration 41000, Testing net (#0)
I0812 10:54:06.044054 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.044064 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.044072 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.045276 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.045300 16297 solver.cpp:343]     Test net output #1: loss = 0.333748 (* 1 = 0.333748 loss)
I0812 10:54:06.045323 16297 solver.cpp:214] Iteration 41000, loss = 0.320776
I0812 10:54:06.045367 16297 solver.cpp:229]     Train net output #0: loss = 0.320776 (* 1 = 0.320776 loss)
I0812 10:54:06.045378 16297 solver.cpp:486] Iteration 41000, lr = 0.0001
I0812 10:54:06.050463 16297 solver.cpp:214] Iteration 41500, loss = 0.319498
I0812 10:54:06.050492 16297 solver.cpp:229]     Train net output #0: loss = 0.319498 (* 1 = 0.319498 loss)
I0812 10:54:06.050503 16297 solver.cpp:486] Iteration 41500, lr = 0.0001
I0812 10:54:06.055785 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.055835 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_42000.caffemodel
I0812 10:54:06.056005 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_42000.solverstate
I0812 10:54:06.056123 16297 solver.cpp:294] Iteration 42000, Testing net (#0)
I0812 10:54:06.056146 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.056155 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.056164 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.057416 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.057458 16297 solver.cpp:343]     Test net output #1: loss = 0.331007 (* 1 = 0.331007 loss)
I0812 10:54:06.057495 16297 solver.cpp:214] Iteration 42000, loss = 0.318236
I0812 10:54:06.057509 16297 solver.cpp:229]     Train net output #0: loss = 0.318236 (* 1 = 0.318236 loss)
I0812 10:54:06.057521 16297 solver.cpp:486] Iteration 42000, lr = 0.0001
I0812 10:54:06.062598 16297 solver.cpp:214] Iteration 42500, loss = 0.316989
I0812 10:54:06.062624 16297 solver.cpp:229]     Train net output #0: loss = 0.316989 (* 1 = 0.316989 loss)
I0812 10:54:06.062645 16297 solver.cpp:486] Iteration 42500, lr = 0.0001
I0812 10:54:06.067708 16297 solver.cpp:294] Iteration 43000, Testing net (#0)
I0812 10:54:06.067724 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.067734 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.067742 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.069066 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.069113 16297 solver.cpp:343]     Test net output #1: loss = 0.32553 (* 1 = 0.32553 loss)
I0812 10:54:06.069150 16297 solver.cpp:214] Iteration 43000, loss = 0.315757
I0812 10:54:06.069165 16297 solver.cpp:229]     Train net output #0: loss = 0.315757 (* 1 = 0.315757 loss)
I0812 10:54:06.069186 16297 solver.cpp:486] Iteration 43000, lr = 0.0001
I0812 10:54:06.074338 16297 solver.cpp:214] Iteration 43500, loss = 0.31454
I0812 10:54:06.074375 16297 solver.cpp:229]     Train net output #0: loss = 0.31454 (* 1 = 0.31454 loss)
I0812 10:54:06.074385 16297 solver.cpp:486] Iteration 43500, lr = 0.0001
I0812 10:54:06.079375 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.079417 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_44000.caffemodel
I0812 10:54:06.079586 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_44000.solverstate
I0812 10:54:06.079704 16297 solver.cpp:294] Iteration 44000, Testing net (#0)
I0812 10:54:06.079730 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.079738 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.079748 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.081020 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.081043 16297 solver.cpp:343]     Test net output #1: loss = 0.323941 (* 1 = 0.323941 loss)
I0812 10:54:06.081069 16297 solver.cpp:214] Iteration 44000, loss = 0.313337
I0812 10:54:06.081084 16297 solver.cpp:229]     Train net output #0: loss = 0.313337 (* 1 = 0.313337 loss)
I0812 10:54:06.081094 16297 solver.cpp:486] Iteration 44000, lr = 0.0001
I0812 10:54:06.086182 16297 solver.cpp:214] Iteration 44500, loss = 0.312148
I0812 10:54:06.086210 16297 solver.cpp:229]     Train net output #0: loss = 0.312148 (* 1 = 0.312148 loss)
I0812 10:54:06.086222 16297 solver.cpp:486] Iteration 44500, lr = 0.0001
I0812 10:54:06.091245 16297 solver.cpp:294] Iteration 45000, Testing net (#0)
I0812 10:54:06.091292 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.091302 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.091310 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.092516 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.092540 16297 solver.cpp:343]     Test net output #1: loss = 0.321574 (* 1 = 0.321574 loss)
I0812 10:54:06.092566 16297 solver.cpp:214] Iteration 45000, loss = 0.310972
I0812 10:54:06.092581 16297 solver.cpp:229]     Train net output #0: loss = 0.310972 (* 1 = 0.310972 loss)
I0812 10:54:06.092592 16297 solver.cpp:486] Iteration 45000, lr = 0.0001
I0812 10:54:06.097710 16297 solver.cpp:214] Iteration 45500, loss = 0.30981
I0812 10:54:06.097738 16297 solver.cpp:229]     Train net output #0: loss = 0.30981 (* 1 = 0.30981 loss)
I0812 10:54:06.097748 16297 solver.cpp:486] Iteration 45500, lr = 0.0001
I0812 10:54:06.102779 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.102819 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_46000.caffemodel
I0812 10:54:06.102990 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_46000.solverstate
I0812 10:54:06.103139 16297 solver.cpp:294] Iteration 46000, Testing net (#0)
I0812 10:54:06.103163 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.103171 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.103181 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.104507 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.104563 16297 solver.cpp:343]     Test net output #1: loss = 0.31644 (* 1 = 0.31644 loss)
I0812 10:54:06.104600 16297 solver.cpp:214] Iteration 46000, loss = 0.308661
I0812 10:54:06.104617 16297 solver.cpp:229]     Train net output #0: loss = 0.308661 (* 1 = 0.308661 loss)
I0812 10:54:06.104631 16297 solver.cpp:486] Iteration 46000, lr = 0.0001
I0812 10:54:06.109664 16297 solver.cpp:214] Iteration 46500, loss = 0.307526
I0812 10:54:06.109690 16297 solver.cpp:229]     Train net output #0: loss = 0.307526 (* 1 = 0.307526 loss)
I0812 10:54:06.109700 16297 solver.cpp:486] Iteration 46500, lr = 0.0001
I0812 10:54:06.114610 16297 solver.cpp:294] Iteration 47000, Testing net (#0)
I0812 10:54:06.114625 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.114634 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.114641 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.115883 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.115922 16297 solver.cpp:343]     Test net output #1: loss = 0.315017 (* 1 = 0.315017 loss)
I0812 10:54:06.115975 16297 solver.cpp:214] Iteration 47000, loss = 0.306402
I0812 10:54:06.116010 16297 solver.cpp:229]     Train net output #0: loss = 0.306402 (* 1 = 0.306402 loss)
I0812 10:54:06.116020 16297 solver.cpp:486] Iteration 47000, lr = 0.0001
I0812 10:54:06.121173 16297 solver.cpp:214] Iteration 47500, loss = 0.305292
I0812 10:54:06.121250 16297 solver.cpp:229]     Train net output #0: loss = 0.305292 (* 1 = 0.305292 loss)
I0812 10:54:06.121261 16297 solver.cpp:486] Iteration 47500, lr = 0.0001
I0812 10:54:06.126255 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.126297 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_48000.caffemodel
I0812 10:54:06.126523 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_48000.solverstate
I0812 10:54:06.126659 16297 solver.cpp:294] Iteration 48000, Testing net (#0)
I0812 10:54:06.126683 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.126693 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.126701 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.127964 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.127985 16297 solver.cpp:343]     Test net output #1: loss = 0.312973 (* 1 = 0.312973 loss)
I0812 10:54:06.128031 16297 solver.cpp:214] Iteration 48000, loss = 0.304193
I0812 10:54:06.128046 16297 solver.cpp:229]     Train net output #0: loss = 0.304193 (* 1 = 0.304193 loss)
I0812 10:54:06.128083 16297 solver.cpp:486] Iteration 48000, lr = 0.0001
I0812 10:54:06.133165 16297 solver.cpp:214] Iteration 48500, loss = 0.303105
I0812 10:54:06.133203 16297 solver.cpp:229]     Train net output #0: loss = 0.303105 (* 1 = 0.303105 loss)
I0812 10:54:06.133213 16297 solver.cpp:486] Iteration 48500, lr = 0.0001
I0812 10:54:06.138342 16297 solver.cpp:294] Iteration 49000, Testing net (#0)
I0812 10:54:06.138367 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.138375 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.138384 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.139672 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.139695 16297 solver.cpp:343]     Test net output #1: loss = 0.308138 (* 1 = 0.308138 loss)
I0812 10:54:06.139740 16297 solver.cpp:214] Iteration 49000, loss = 0.30203
I0812 10:54:06.139765 16297 solver.cpp:229]     Train net output #0: loss = 0.30203 (* 1 = 0.30203 loss)
I0812 10:54:06.139786 16297 solver.cpp:486] Iteration 49000, lr = 0.0001
I0812 10:54:06.144829 16297 solver.cpp:214] Iteration 49500, loss = 0.300965
I0812 10:54:06.144853 16297 solver.cpp:229]     Train net output #0: loss = 0.300965 (* 1 = 0.300965 loss)
I0812 10:54:06.144863 16297 solver.cpp:486] Iteration 49500, lr = 0.0001
I0812 10:54:06.149766 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.149801 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_50000.caffemodel
I0812 10:54:06.150013 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_50000.solverstate
I0812 10:54:06.150195 16297 solver.cpp:294] Iteration 50000, Testing net (#0)
I0812 10:54:06.150230 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.150239 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.150249 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.151507 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.151535 16297 solver.cpp:343]     Test net output #1: loss = 0.30686 (* 1 = 0.30686 loss)
I0812 10:54:06.151559 16297 solver.cpp:214] Iteration 50000, loss = 0.299912
I0812 10:54:06.151574 16297 solver.cpp:229]     Train net output #0: loss = 0.299912 (* 1 = 0.299912 loss)
I0812 10:54:06.151584 16297 solver.cpp:486] Iteration 50000, lr = 1e-05
I0812 10:54:06.156647 16297 solver.cpp:214] Iteration 50500, loss = 0.299805
I0812 10:54:06.156679 16297 solver.cpp:229]     Train net output #0: loss = 0.299805 (* 1 = 0.299805 loss)
I0812 10:54:06.156690 16297 solver.cpp:486] Iteration 50500, lr = 1e-05
I0812 10:54:06.161700 16297 solver.cpp:294] Iteration 51000, Testing net (#0)
I0812 10:54:06.161725 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.161733 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.161743 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.162997 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.163028 16297 solver.cpp:343]     Test net output #1: loss = 0.307377 (* 1 = 0.307377 loss)
I0812 10:54:06.163050 16297 solver.cpp:214] Iteration 51000, loss = 0.2997
I0812 10:54:06.163086 16297 solver.cpp:229]     Train net output #0: loss = 0.2997 (* 1 = 0.2997 loss)
I0812 10:54:06.163096 16297 solver.cpp:486] Iteration 51000, lr = 1e-05
I0812 10:54:06.168169 16297 solver.cpp:214] Iteration 51500, loss = 0.299595
I0812 10:54:06.168196 16297 solver.cpp:229]     Train net output #0: loss = 0.299595 (* 1 = 0.299595 loss)
I0812 10:54:06.168206 16297 solver.cpp:486] Iteration 51500, lr = 1e-05
I0812 10:54:06.173267 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.173332 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_52000.caffemodel
I0812 10:54:06.173537 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_52000.solverstate
I0812 10:54:06.173652 16297 solver.cpp:294] Iteration 52000, Testing net (#0)
I0812 10:54:06.173687 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.173697 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.173741 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.174952 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.174973 16297 solver.cpp:343]     Test net output #1: loss = 0.305004 (* 1 = 0.305004 loss)
I0812 10:54:06.174998 16297 solver.cpp:214] Iteration 52000, loss = 0.299491
I0812 10:54:06.175014 16297 solver.cpp:229]     Train net output #0: loss = 0.299491 (* 1 = 0.299491 loss)
I0812 10:54:06.175024 16297 solver.cpp:486] Iteration 52000, lr = 1e-05
I0812 10:54:06.180037 16297 solver.cpp:214] Iteration 52500, loss = 0.299386
I0812 10:54:06.180066 16297 solver.cpp:229]     Train net output #0: loss = 0.299386 (* 1 = 0.299386 loss)
I0812 10:54:06.180076 16297 solver.cpp:486] Iteration 52500, lr = 1e-05
I0812 10:54:06.185061 16297 solver.cpp:294] Iteration 53000, Testing net (#0)
I0812 10:54:06.185086 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.185094 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.185102 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.186367 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.186391 16297 solver.cpp:343]     Test net output #1: loss = 0.306071 (* 1 = 0.306071 loss)
I0812 10:54:06.186437 16297 solver.cpp:214] Iteration 53000, loss = 0.299282
I0812 10:54:06.186461 16297 solver.cpp:229]     Train net output #0: loss = 0.299282 (* 1 = 0.299282 loss)
I0812 10:54:06.186472 16297 solver.cpp:486] Iteration 53000, lr = 1e-05
I0812 10:54:06.191546 16297 solver.cpp:214] Iteration 53500, loss = 0.299178
I0812 10:54:06.191577 16297 solver.cpp:229]     Train net output #0: loss = 0.299178 (* 1 = 0.299178 loss)
I0812 10:54:06.191587 16297 solver.cpp:486] Iteration 53500, lr = 1e-05
I0812 10:54:06.196506 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.196550 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_54000.caffemodel
I0812 10:54:06.196780 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_54000.solverstate
I0812 10:54:06.196920 16297 solver.cpp:294] Iteration 54000, Testing net (#0)
I0812 10:54:06.196957 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.196976 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.196985 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.198252 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.198283 16297 solver.cpp:343]     Test net output #1: loss = 0.306604 (* 1 = 0.306604 loss)
I0812 10:54:06.198318 16297 solver.cpp:214] Iteration 54000, loss = 0.299075
I0812 10:54:06.198333 16297 solver.cpp:229]     Train net output #0: loss = 0.299075 (* 1 = 0.299075 loss)
I0812 10:54:06.198343 16297 solver.cpp:486] Iteration 54000, lr = 1e-05
I0812 10:54:06.203341 16297 solver.cpp:214] Iteration 54500, loss = 0.298971
I0812 10:54:06.203369 16297 solver.cpp:229]     Train net output #0: loss = 0.298971 (* 1 = 0.298971 loss)
I0812 10:54:06.203379 16297 solver.cpp:486] Iteration 54500, lr = 1e-05
I0812 10:54:06.208483 16297 solver.cpp:294] Iteration 55000, Testing net (#0)
I0812 10:54:06.208503 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.208510 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.208518 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.209826 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.209859 16297 solver.cpp:343]     Test net output #1: loss = 0.304237 (* 1 = 0.304237 loss)
I0812 10:54:06.209884 16297 solver.cpp:214] Iteration 55000, loss = 0.298867
I0812 10:54:06.209909 16297 solver.cpp:229]     Train net output #0: loss = 0.298867 (* 1 = 0.298867 loss)
I0812 10:54:06.209918 16297 solver.cpp:486] Iteration 55000, lr = 1e-05
I0812 10:54:06.215000 16297 solver.cpp:214] Iteration 55500, loss = 0.298764
I0812 10:54:06.215023 16297 solver.cpp:229]     Train net output #0: loss = 0.298764 (* 1 = 0.298764 loss)
I0812 10:54:06.215032 16297 solver.cpp:486] Iteration 55500, lr = 1e-05
I0812 10:54:06.220015 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.220090 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_56000.caffemodel
I0812 10:54:06.220247 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_56000.solverstate
I0812 10:54:06.220372 16297 solver.cpp:294] Iteration 56000, Testing net (#0)
I0812 10:54:06.220407 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.220415 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.220424 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.221705 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.221732 16297 solver.cpp:343]     Test net output #1: loss = 0.305297 (* 1 = 0.305297 loss)
I0812 10:54:06.221760 16297 solver.cpp:214] Iteration 56000, loss = 0.298661
I0812 10:54:06.221774 16297 solver.cpp:229]     Train net output #0: loss = 0.298661 (* 1 = 0.298661 loss)
I0812 10:54:06.221784 16297 solver.cpp:486] Iteration 56000, lr = 1e-05
I0812 10:54:06.226800 16297 solver.cpp:214] Iteration 56500, loss = 0.298558
I0812 10:54:06.226831 16297 solver.cpp:229]     Train net output #0: loss = 0.298558 (* 1 = 0.298558 loss)
I0812 10:54:06.226841 16297 solver.cpp:486] Iteration 56500, lr = 1e-05
I0812 10:54:06.231788 16297 solver.cpp:294] Iteration 57000, Testing net (#0)
I0812 10:54:06.231806 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.231814 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.231822 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.233059 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.233093 16297 solver.cpp:343]     Test net output #1: loss = 0.305836 (* 1 = 0.305836 loss)
I0812 10:54:06.233125 16297 solver.cpp:214] Iteration 57000, loss = 0.298455
I0812 10:54:06.233139 16297 solver.cpp:229]     Train net output #0: loss = 0.298455 (* 1 = 0.298455 loss)
I0812 10:54:06.233158 16297 solver.cpp:486] Iteration 57000, lr = 1e-05
I0812 10:54:06.238373 16297 solver.cpp:214] Iteration 57500, loss = 0.298352
I0812 10:54:06.238463 16297 solver.cpp:229]     Train net output #0: loss = 0.298352 (* 1 = 0.298352 loss)
I0812 10:54:06.238476 16297 solver.cpp:486] Iteration 57500, lr = 1e-05
I0812 10:54:06.243383 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.243419 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_58000.caffemodel
I0812 10:54:06.243589 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_58000.solverstate
I0812 10:54:06.243732 16297 solver.cpp:294] Iteration 58000, Testing net (#0)
I0812 10:54:06.243757 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.243774 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.243783 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.245124 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.245157 16297 solver.cpp:343]     Test net output #1: loss = 0.303476 (* 1 = 0.303476 loss)
I0812 10:54:06.245193 16297 solver.cpp:214] Iteration 58000, loss = 0.298249
I0812 10:54:06.245208 16297 solver.cpp:229]     Train net output #0: loss = 0.298249 (* 1 = 0.298249 loss)
I0812 10:54:06.245218 16297 solver.cpp:486] Iteration 58000, lr = 1e-05
I0812 10:54:06.250310 16297 solver.cpp:214] Iteration 58500, loss = 0.298147
I0812 10:54:06.250334 16297 solver.cpp:229]     Train net output #0: loss = 0.298147 (* 1 = 0.298147 loss)
I0812 10:54:06.250344 16297 solver.cpp:486] Iteration 58500, lr = 1e-05
I0812 10:54:06.255342 16297 solver.cpp:294] Iteration 59000, Testing net (#0)
I0812 10:54:06.255363 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.255372 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.255379 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.256620 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.256654 16297 solver.cpp:343]     Test net output #1: loss = 0.304529 (* 1 = 0.304529 loss)
I0812 10:54:06.256680 16297 solver.cpp:214] Iteration 59000, loss = 0.298044
I0812 10:54:06.256705 16297 solver.cpp:229]     Train net output #0: loss = 0.298044 (* 1 = 0.298044 loss)
I0812 10:54:06.256752 16297 solver.cpp:486] Iteration 59000, lr = 1e-05
I0812 10:54:06.261898 16297 solver.cpp:214] Iteration 59500, loss = 0.297942
I0812 10:54:06.261924 16297 solver.cpp:229]     Train net output #0: loss = 0.297942 (* 1 = 0.297942 loss)
I0812 10:54:06.261934 16297 solver.cpp:486] Iteration 59500, lr = 1e-05
I0812 10:54:06.266870 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.266906 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_60000.caffemodel
I0812 10:54:06.267074 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_60000.solverstate
I0812 10:54:06.267225 16297 solver.cpp:294] Iteration 60000, Testing net (#0)
I0812 10:54:06.267259 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.267268 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.267277 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.268556 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.268600 16297 solver.cpp:343]     Test net output #1: loss = 0.305075 (* 1 = 0.305075 loss)
I0812 10:54:06.268626 16297 solver.cpp:214] Iteration 60000, loss = 0.29784
I0812 10:54:06.268641 16297 solver.cpp:229]     Train net output #0: loss = 0.29784 (* 1 = 0.29784 loss)
I0812 10:54:06.268652 16297 solver.cpp:486] Iteration 60000, lr = 1e-05
I0812 10:54:06.273736 16297 solver.cpp:214] Iteration 60500, loss = 0.297737
I0812 10:54:06.273767 16297 solver.cpp:229]     Train net output #0: loss = 0.297737 (* 1 = 0.297737 loss)
I0812 10:54:06.273777 16297 solver.cpp:486] Iteration 60500, lr = 1e-05
I0812 10:54:06.278807 16297 solver.cpp:294] Iteration 61000, Testing net (#0)
I0812 10:54:06.278827 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.278836 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.278846 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.280051 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.280076 16297 solver.cpp:343]     Test net output #1: loss = 0.30272 (* 1 = 0.30272 loss)
I0812 10:54:06.280100 16297 solver.cpp:214] Iteration 61000, loss = 0.297635
I0812 10:54:06.280115 16297 solver.cpp:229]     Train net output #0: loss = 0.297635 (* 1 = 0.297635 loss)
I0812 10:54:06.280127 16297 solver.cpp:486] Iteration 61000, lr = 1e-05
I0812 10:54:06.285164 16297 solver.cpp:214] Iteration 61500, loss = 0.297533
I0812 10:54:06.285193 16297 solver.cpp:229]     Train net output #0: loss = 0.297533 (* 1 = 0.297533 loss)
I0812 10:54:06.285203 16297 solver.cpp:486] Iteration 61500, lr = 1e-05
I0812 10:54:06.290256 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.290329 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_62000.caffemodel
I0812 10:54:06.290580 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_62000.solverstate
I0812 10:54:06.290729 16297 solver.cpp:294] Iteration 62000, Testing net (#0)
I0812 10:54:06.290762 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.290771 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.290791 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.292029 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.292050 16297 solver.cpp:343]     Test net output #1: loss = 0.303768 (* 1 = 0.303768 loss)
I0812 10:54:06.292075 16297 solver.cpp:214] Iteration 62000, loss = 0.297431
I0812 10:54:06.292090 16297 solver.cpp:229]     Train net output #0: loss = 0.297431 (* 1 = 0.297431 loss)
I0812 10:54:06.292103 16297 solver.cpp:486] Iteration 62000, lr = 1e-05
I0812 10:54:06.297224 16297 solver.cpp:214] Iteration 62500, loss = 0.297329
I0812 10:54:06.297250 16297 solver.cpp:229]     Train net output #0: loss = 0.297329 (* 1 = 0.297329 loss)
I0812 10:54:06.297260 16297 solver.cpp:486] Iteration 62500, lr = 1e-05
I0812 10:54:06.302342 16297 solver.cpp:294] Iteration 63000, Testing net (#0)
I0812 10:54:06.302361 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.302404 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.302415 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.303678 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.303701 16297 solver.cpp:343]     Test net output #1: loss = 0.30432 (* 1 = 0.30432 loss)
I0812 10:54:06.303726 16297 solver.cpp:214] Iteration 63000, loss = 0.297228
I0812 10:54:06.303742 16297 solver.cpp:229]     Train net output #0: loss = 0.297228 (* 1 = 0.297228 loss)
I0812 10:54:06.303753 16297 solver.cpp:486] Iteration 63000, lr = 1e-05
I0812 10:54:06.308786 16297 solver.cpp:214] Iteration 63500, loss = 0.297126
I0812 10:54:06.308814 16297 solver.cpp:229]     Train net output #0: loss = 0.297126 (* 1 = 0.297126 loss)
I0812 10:54:06.308823 16297 solver.cpp:486] Iteration 63500, lr = 1e-05
I0812 10:54:06.313725 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.313772 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_64000.caffemodel
I0812 10:54:06.313979 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_64000.solverstate
I0812 10:54:06.314124 16297 solver.cpp:294] Iteration 64000, Testing net (#0)
I0812 10:54:06.314159 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.314168 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.314178 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.315418 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.315439 16297 solver.cpp:343]     Test net output #1: loss = 0.301972 (* 1 = 0.301972 loss)
I0812 10:54:06.315464 16297 solver.cpp:214] Iteration 64000, loss = 0.297024
I0812 10:54:06.315479 16297 solver.cpp:229]     Train net output #0: loss = 0.297024 (* 1 = 0.297024 loss)
I0812 10:54:06.315490 16297 solver.cpp:486] Iteration 64000, lr = 1e-05
I0812 10:54:06.320570 16297 solver.cpp:214] Iteration 64500, loss = 0.296923
I0812 10:54:06.320644 16297 solver.cpp:229]     Train net output #0: loss = 0.296923 (* 1 = 0.296923 loss)
I0812 10:54:06.320658 16297 solver.cpp:486] Iteration 64500, lr = 1e-05
I0812 10:54:06.325850 16297 solver.cpp:294] Iteration 65000, Testing net (#0)
I0812 10:54:06.325875 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.325882 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.325892 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.327100 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.327126 16297 solver.cpp:343]     Test net output #1: loss = 0.303013 (* 1 = 0.303013 loss)
I0812 10:54:06.327150 16297 solver.cpp:214] Iteration 65000, loss = 0.296821
I0812 10:54:06.327164 16297 solver.cpp:229]     Train net output #0: loss = 0.296821 (* 1 = 0.296821 loss)
I0812 10:54:06.327175 16297 solver.cpp:486] Iteration 65000, lr = 1e-05
I0812 10:54:06.332197 16297 solver.cpp:214] Iteration 65500, loss = 0.29672
I0812 10:54:06.332232 16297 solver.cpp:229]     Train net output #0: loss = 0.29672 (* 1 = 0.29672 loss)
I0812 10:54:06.332243 16297 solver.cpp:486] Iteration 65500, lr = 1e-05
I0812 10:54:06.337307 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.337360 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_66000.caffemodel
I0812 10:54:06.337545 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_66000.solverstate
I0812 10:54:06.337692 16297 solver.cpp:294] Iteration 66000, Testing net (#0)
I0812 10:54:06.337712 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.337724 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.337736 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.339026 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.339056 16297 solver.cpp:343]     Test net output #1: loss = 0.303571 (* 1 = 0.303571 loss)
I0812 10:54:06.339083 16297 solver.cpp:214] Iteration 66000, loss = 0.296619
I0812 10:54:06.339099 16297 solver.cpp:229]     Train net output #0: loss = 0.296619 (* 1 = 0.296619 loss)
I0812 10:54:06.339133 16297 solver.cpp:486] Iteration 66000, lr = 1e-05
I0812 10:54:06.344195 16297 solver.cpp:214] Iteration 66500, loss = 0.296518
I0812 10:54:06.344240 16297 solver.cpp:229]     Train net output #0: loss = 0.296518 (* 1 = 0.296518 loss)
I0812 10:54:06.344251 16297 solver.cpp:486] Iteration 66500, lr = 1e-05
I0812 10:54:06.349288 16297 solver.cpp:294] Iteration 67000, Testing net (#0)
I0812 10:54:06.349304 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.349313 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.349320 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.350600 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.350633 16297 solver.cpp:343]     Test net output #1: loss = 0.30123 (* 1 = 0.30123 loss)
I0812 10:54:06.350678 16297 solver.cpp:214] Iteration 67000, loss = 0.296417
I0812 10:54:06.350703 16297 solver.cpp:229]     Train net output #0: loss = 0.296417 (* 1 = 0.296417 loss)
I0812 10:54:06.350725 16297 solver.cpp:486] Iteration 67000, lr = 1e-05
I0812 10:54:06.355785 16297 solver.cpp:214] Iteration 67500, loss = 0.296317
I0812 10:54:06.355816 16297 solver.cpp:229]     Train net output #0: loss = 0.296317 (* 1 = 0.296317 loss)
I0812 10:54:06.355826 16297 solver.cpp:486] Iteration 67500, lr = 1e-05
I0812 10:54:06.360924 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.360960 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_68000.caffemodel
I0812 10:54:06.361127 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_68000.solverstate
I0812 10:54:06.361248 16297 solver.cpp:294] Iteration 68000, Testing net (#0)
I0812 10:54:06.361271 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.361281 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.361291 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.362534 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.362565 16297 solver.cpp:343]     Test net output #1: loss = 0.302264 (* 1 = 0.302264 loss)
I0812 10:54:06.362591 16297 solver.cpp:214] Iteration 68000, loss = 0.296216
I0812 10:54:06.362625 16297 solver.cpp:229]     Train net output #0: loss = 0.296216 (* 1 = 0.296216 loss)
I0812 10:54:06.362637 16297 solver.cpp:486] Iteration 68000, lr = 1e-05
I0812 10:54:06.367771 16297 solver.cpp:214] Iteration 68500, loss = 0.296115
I0812 10:54:06.367799 16297 solver.cpp:229]     Train net output #0: loss = 0.296115 (* 1 = 0.296115 loss)
I0812 10:54:06.367810 16297 solver.cpp:486] Iteration 68500, lr = 1e-05
I0812 10:54:06.372941 16297 solver.cpp:294] Iteration 69000, Testing net (#0)
I0812 10:54:06.372964 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.372972 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.372982 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.374191 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.374215 16297 solver.cpp:343]     Test net output #1: loss = 0.302828 (* 1 = 0.302828 loss)
I0812 10:54:06.374239 16297 solver.cpp:214] Iteration 69000, loss = 0.296015
I0812 10:54:06.374253 16297 solver.cpp:229]     Train net output #0: loss = 0.296015 (* 1 = 0.296015 loss)
I0812 10:54:06.374264 16297 solver.cpp:486] Iteration 69000, lr = 1e-05
I0812 10:54:06.379353 16297 solver.cpp:214] Iteration 69500, loss = 0.295915
I0812 10:54:06.379381 16297 solver.cpp:229]     Train net output #0: loss = 0.295915 (* 1 = 0.295915 loss)
I0812 10:54:06.379390 16297 solver.cpp:486] Iteration 69500, lr = 1e-05
I0812 10:54:06.384488 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.384531 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_70000.caffemodel
I0812 10:54:06.384740 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_70000.solverstate
I0812 10:54:06.384878 16297 solver.cpp:294] Iteration 70000, Testing net (#0)
I0812 10:54:06.384923 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.384932 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.384954 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.386180 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.386204 16297 solver.cpp:343]     Test net output #1: loss = 0.300493 (* 1 = 0.300493 loss)
I0812 10:54:06.386229 16297 solver.cpp:214] Iteration 70000, loss = 0.295814
I0812 10:54:06.386245 16297 solver.cpp:229]     Train net output #0: loss = 0.295814 (* 1 = 0.295814 loss)
I0812 10:54:06.386256 16297 solver.cpp:486] Iteration 70000, lr = 1e-05
I0812 10:54:06.391330 16297 solver.cpp:214] Iteration 70500, loss = 0.295714
I0812 10:54:06.391360 16297 solver.cpp:229]     Train net output #0: loss = 0.295714 (* 1 = 0.295714 loss)
I0812 10:54:06.391371 16297 solver.cpp:486] Iteration 70500, lr = 1e-05
I0812 10:54:06.396368 16297 solver.cpp:294] Iteration 71000, Testing net (#0)
I0812 10:54:06.396384 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.396391 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.396400 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.397696 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.397716 16297 solver.cpp:343]     Test net output #1: loss = 0.301522 (* 1 = 0.301522 loss)
I0812 10:54:06.397771 16297 solver.cpp:214] Iteration 71000, loss = 0.295614
I0812 10:54:06.397796 16297 solver.cpp:229]     Train net output #0: loss = 0.295614 (* 1 = 0.295614 loss)
I0812 10:54:06.397806 16297 solver.cpp:486] Iteration 71000, lr = 1e-05
I0812 10:54:06.402897 16297 solver.cpp:214] Iteration 71500, loss = 0.295514
I0812 10:54:06.402923 16297 solver.cpp:229]     Train net output #0: loss = 0.295514 (* 1 = 0.295514 loss)
I0812 10:54:06.402932 16297 solver.cpp:486] Iteration 71500, lr = 1e-05
I0812 10:54:06.408011 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.408051 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_72000.caffemodel
I0812 10:54:06.408221 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_72000.solverstate
I0812 10:54:06.408339 16297 solver.cpp:294] Iteration 72000, Testing net (#0)
I0812 10:54:06.408362 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.408371 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.408381 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.409617 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.409638 16297 solver.cpp:343]     Test net output #1: loss = 0.302092 (* 1 = 0.302092 loss)
I0812 10:54:06.409672 16297 solver.cpp:214] Iteration 72000, loss = 0.295414
I0812 10:54:06.409687 16297 solver.cpp:229]     Train net output #0: loss = 0.295414 (* 1 = 0.295414 loss)
I0812 10:54:06.409708 16297 solver.cpp:486] Iteration 72000, lr = 1e-05
I0812 10:54:06.414708 16297 solver.cpp:214] Iteration 72500, loss = 0.295315
I0812 10:54:06.414731 16297 solver.cpp:229]     Train net output #0: loss = 0.295315 (* 1 = 0.295315 loss)
I0812 10:54:06.414742 16297 solver.cpp:486] Iteration 72500, lr = 1e-05
I0812 10:54:06.419687 16297 solver.cpp:294] Iteration 73000, Testing net (#0)
I0812 10:54:06.419703 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.419710 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.419718 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.421133 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.421198 16297 solver.cpp:343]     Test net output #1: loss = 0.299764 (* 1 = 0.299764 loss)
I0812 10:54:06.421237 16297 solver.cpp:214] Iteration 73000, loss = 0.295215
I0812 10:54:06.421255 16297 solver.cpp:229]     Train net output #0: loss = 0.295215 (* 1 = 0.295215 loss)
I0812 10:54:06.421269 16297 solver.cpp:486] Iteration 73000, lr = 1e-05
I0812 10:54:06.426290 16297 solver.cpp:214] Iteration 73500, loss = 0.295116
I0812 10:54:06.426319 16297 solver.cpp:229]     Train net output #0: loss = 0.295116 (* 1 = 0.295116 loss)
I0812 10:54:06.426331 16297 solver.cpp:486] Iteration 73500, lr = 1e-05
I0812 10:54:06.431306 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.431380 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_74000.caffemodel
I0812 10:54:06.431560 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_74000.solverstate
I0812 10:54:06.431679 16297 solver.cpp:294] Iteration 74000, Testing net (#0)
I0812 10:54:06.431702 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.431711 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.431720 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.433034 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.433055 16297 solver.cpp:343]     Test net output #1: loss = 0.300787 (* 1 = 0.300787 loss)
I0812 10:54:06.433081 16297 solver.cpp:214] Iteration 74000, loss = 0.295016
I0812 10:54:06.433096 16297 solver.cpp:229]     Train net output #0: loss = 0.295016 (* 1 = 0.295016 loss)
I0812 10:54:06.433107 16297 solver.cpp:486] Iteration 74000, lr = 1e-05
I0812 10:54:06.438192 16297 solver.cpp:214] Iteration 74500, loss = 0.294917
I0812 10:54:06.438285 16297 solver.cpp:229]     Train net output #0: loss = 0.294917 (* 1 = 0.294917 loss)
I0812 10:54:06.438300 16297 solver.cpp:486] Iteration 74500, lr = 1e-05
I0812 10:54:06.443377 16297 solver.cpp:294] Iteration 75000, Testing net (#0)
I0812 10:54:06.443410 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.443419 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.443429 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.444731 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.444763 16297 solver.cpp:343]     Test net output #1: loss = 0.301364 (* 1 = 0.301364 loss)
I0812 10:54:06.444789 16297 solver.cpp:214] Iteration 75000, loss = 0.294817
I0812 10:54:06.444803 16297 solver.cpp:229]     Train net output #0: loss = 0.294817 (* 1 = 0.294817 loss)
I0812 10:54:06.444813 16297 solver.cpp:486] Iteration 75000, lr = 1e-05
I0812 10:54:06.449897 16297 solver.cpp:214] Iteration 75500, loss = 0.294717
I0812 10:54:06.449925 16297 solver.cpp:229]     Train net output #0: loss = 0.294717 (* 1 = 0.294717 loss)
I0812 10:54:06.449935 16297 solver.cpp:486] Iteration 75500, lr = 1e-05
I0812 10:54:06.455086 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.455133 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_76000.caffemodel
I0812 10:54:06.455302 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_76000.solverstate
I0812 10:54:06.455420 16297 solver.cpp:294] Iteration 76000, Testing net (#0)
I0812 10:54:06.455445 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.455454 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.455464 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.456706 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.456727 16297 solver.cpp:343]     Test net output #1: loss = 0.299043 (* 1 = 0.299043 loss)
I0812 10:54:06.456761 16297 solver.cpp:214] Iteration 76000, loss = 0.294617
I0812 10:54:06.456776 16297 solver.cpp:229]     Train net output #0: loss = 0.294617 (* 1 = 0.294617 loss)
I0812 10:54:06.456787 16297 solver.cpp:486] Iteration 76000, lr = 1e-05
I0812 10:54:06.461819 16297 solver.cpp:214] Iteration 76500, loss = 0.294517
I0812 10:54:06.461843 16297 solver.cpp:229]     Train net output #0: loss = 0.294517 (* 1 = 0.294517 loss)
I0812 10:54:06.461853 16297 solver.cpp:486] Iteration 76500, lr = 1e-05
I0812 10:54:06.466953 16297 solver.cpp:294] Iteration 77000, Testing net (#0)
I0812 10:54:06.466969 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.466977 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.466985 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.468299 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.468322 16297 solver.cpp:343]     Test net output #1: loss = 0.300061 (* 1 = 0.300061 loss)
I0812 10:54:06.468346 16297 solver.cpp:214] Iteration 77000, loss = 0.294418
I0812 10:54:06.468360 16297 solver.cpp:229]     Train net output #0: loss = 0.294418 (* 1 = 0.294418 loss)
I0812 10:54:06.468405 16297 solver.cpp:486] Iteration 77000, lr = 1e-05
I0812 10:54:06.473502 16297 solver.cpp:214] Iteration 77500, loss = 0.294319
I0812 10:54:06.473532 16297 solver.cpp:229]     Train net output #0: loss = 0.294319 (* 1 = 0.294319 loss)
I0812 10:54:06.473542 16297 solver.cpp:486] Iteration 77500, lr = 1e-05
I0812 10:54:06.478662 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.478708 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_78000.caffemodel
I0812 10:54:06.478873 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_78000.solverstate
I0812 10:54:06.478991 16297 solver.cpp:294] Iteration 78000, Testing net (#0)
I0812 10:54:06.479015 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.479024 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.479034 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.480245 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.480267 16297 solver.cpp:343]     Test net output #1: loss = 0.300645 (* 1 = 0.300645 loss)
I0812 10:54:06.480291 16297 solver.cpp:214] Iteration 78000, loss = 0.29422
I0812 10:54:06.480306 16297 solver.cpp:229]     Train net output #0: loss = 0.29422 (* 1 = 0.29422 loss)
I0812 10:54:06.480317 16297 solver.cpp:486] Iteration 78000, lr = 1e-05
I0812 10:54:06.485471 16297 solver.cpp:214] Iteration 78500, loss = 0.294121
I0812 10:54:06.485499 16297 solver.cpp:229]     Train net output #0: loss = 0.294121 (* 1 = 0.294121 loss)
I0812 10:54:06.485509 16297 solver.cpp:486] Iteration 78500, lr = 1e-05
I0812 10:54:06.490578 16297 solver.cpp:294] Iteration 79000, Testing net (#0)
I0812 10:54:06.490599 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.490607 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.490615 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.491822 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.491844 16297 solver.cpp:343]     Test net output #1: loss = 0.298329 (* 1 = 0.298329 loss)
I0812 10:54:06.491868 16297 solver.cpp:214] Iteration 79000, loss = 0.294022
I0812 10:54:06.491883 16297 solver.cpp:229]     Train net output #0: loss = 0.294022 (* 1 = 0.294022 loss)
I0812 10:54:06.491893 16297 solver.cpp:486] Iteration 79000, lr = 1e-05
I0812 10:54:06.496906 16297 solver.cpp:214] Iteration 79500, loss = 0.293924
I0812 10:54:06.496927 16297 solver.cpp:229]     Train net output #0: loss = 0.293924 (* 1 = 0.293924 loss)
I0812 10:54:06.496938 16297 solver.cpp:486] Iteration 79500, lr = 1e-05
I0812 10:54:06.501982 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.502022 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_80000.caffemodel
I0812 10:54:06.502218 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_80000.solverstate
I0812 10:54:06.502333 16297 solver.cpp:294] Iteration 80000, Testing net (#0)
I0812 10:54:06.502346 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.502377 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.502396 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.503651 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.503672 16297 solver.cpp:343]     Test net output #1: loss = 0.299342 (* 1 = 0.299342 loss)
I0812 10:54:06.503696 16297 solver.cpp:214] Iteration 80000, loss = 0.293825
I0812 10:54:06.503712 16297 solver.cpp:229]     Train net output #0: loss = 0.293825 (* 1 = 0.293825 loss)
I0812 10:54:06.503722 16297 solver.cpp:486] Iteration 80000, lr = 1e-05
I0812 10:54:06.508772 16297 solver.cpp:214] Iteration 80500, loss = 0.293727
I0812 10:54:06.508815 16297 solver.cpp:229]     Train net output #0: loss = 0.293727 (* 1 = 0.293727 loss)
I0812 10:54:06.508826 16297 solver.cpp:486] Iteration 80500, lr = 1e-05
I0812 10:54:06.513932 16297 solver.cpp:294] Iteration 81000, Testing net (#0)
I0812 10:54:06.513948 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.513980 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.514000 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.515250 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.515274 16297 solver.cpp:343]     Test net output #1: loss = 0.29993 (* 1 = 0.29993 loss)
I0812 10:54:06.515296 16297 solver.cpp:214] Iteration 81000, loss = 0.293628
I0812 10:54:06.515311 16297 solver.cpp:229]     Train net output #0: loss = 0.293628 (* 1 = 0.293628 loss)
I0812 10:54:06.515321 16297 solver.cpp:486] Iteration 81000, lr = 1e-05
I0812 10:54:06.520432 16297 solver.cpp:214] Iteration 81500, loss = 0.293529
I0812 10:54:06.520464 16297 solver.cpp:229]     Train net output #0: loss = 0.293529 (* 1 = 0.293529 loss)
I0812 10:54:06.520475 16297 solver.cpp:486] Iteration 81500, lr = 1e-05
I0812 10:54:06.525642 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.525686 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_82000.caffemodel
I0812 10:54:06.525876 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_82000.solverstate
I0812 10:54:06.525995 16297 solver.cpp:294] Iteration 82000, Testing net (#0)
I0812 10:54:06.526028 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.526048 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.526067 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.527389 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.527431 16297 solver.cpp:343]     Test net output #1: loss = 0.297621 (* 1 = 0.297621 loss)
I0812 10:54:06.527467 16297 solver.cpp:214] Iteration 82000, loss = 0.293431
I0812 10:54:06.527482 16297 solver.cpp:229]     Train net output #0: loss = 0.293431 (* 1 = 0.293431 loss)
I0812 10:54:06.527493 16297 solver.cpp:486] Iteration 82000, lr = 1e-05
I0812 10:54:06.532563 16297 solver.cpp:214] Iteration 82500, loss = 0.293332
I0812 10:54:06.532613 16297 solver.cpp:229]     Train net output #0: loss = 0.293332 (* 1 = 0.293332 loss)
I0812 10:54:06.532624 16297 solver.cpp:486] Iteration 82500, lr = 1e-05
I0812 10:54:06.537737 16297 solver.cpp:294] Iteration 83000, Testing net (#0)
I0812 10:54:06.537763 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.537771 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.537780 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.539078 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.539140 16297 solver.cpp:343]     Test net output #1: loss = 0.298628 (* 1 = 0.298628 loss)
I0812 10:54:06.539180 16297 solver.cpp:214] Iteration 83000, loss = 0.293234
I0812 10:54:06.539196 16297 solver.cpp:229]     Train net output #0: loss = 0.293234 (* 1 = 0.293234 loss)
I0812 10:54:06.539208 16297 solver.cpp:486] Iteration 83000, lr = 1e-05
I0812 10:54:06.544425 16297 solver.cpp:214] Iteration 83500, loss = 0.293136
I0812 10:54:06.544535 16297 solver.cpp:229]     Train net output #0: loss = 0.293136 (* 1 = 0.293136 loss)
I0812 10:54:06.544551 16297 solver.cpp:486] Iteration 83500, lr = 1e-05
I0812 10:54:06.549650 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.549708 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_84000.caffemodel
I0812 10:54:06.549901 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_84000.solverstate
I0812 10:54:06.550047 16297 solver.cpp:294] Iteration 84000, Testing net (#0)
I0812 10:54:06.550091 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.550101 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.550110 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.551329 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.551352 16297 solver.cpp:343]     Test net output #1: loss = 0.299222 (* 1 = 0.299222 loss)
I0812 10:54:06.551376 16297 solver.cpp:214] Iteration 84000, loss = 0.293038
I0812 10:54:06.551393 16297 solver.cpp:229]     Train net output #0: loss = 0.293038 (* 1 = 0.293038 loss)
I0812 10:54:06.551403 16297 solver.cpp:486] Iteration 84000, lr = 1e-05
I0812 10:54:06.556502 16297 solver.cpp:214] Iteration 84500, loss = 0.29294
I0812 10:54:06.556538 16297 solver.cpp:229]     Train net output #0: loss = 0.29294 (* 1 = 0.29294 loss)
I0812 10:54:06.556550 16297 solver.cpp:486] Iteration 84500, lr = 1e-05
I0812 10:54:06.561532 16297 solver.cpp:294] Iteration 85000, Testing net (#0)
I0812 10:54:06.561547 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.561554 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.561563 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.562840 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.562860 16297 solver.cpp:343]     Test net output #1: loss = 0.296918 (* 1 = 0.296918 loss)
I0812 10:54:06.562903 16297 solver.cpp:214] Iteration 85000, loss = 0.292842
I0812 10:54:06.562927 16297 solver.cpp:229]     Train net output #0: loss = 0.292842 (* 1 = 0.292842 loss)
I0812 10:54:06.562938 16297 solver.cpp:486] Iteration 85000, lr = 1e-05
I0812 10:54:06.567984 16297 solver.cpp:214] Iteration 85500, loss = 0.292744
I0812 10:54:06.568011 16297 solver.cpp:229]     Train net output #0: loss = 0.292744 (* 1 = 0.292744 loss)
I0812 10:54:06.568019 16297 solver.cpp:486] Iteration 85500, lr = 1e-05
I0812 10:54:06.573125 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.573179 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_86000.caffemodel
I0812 10:54:06.573367 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_86000.solverstate
I0812 10:54:06.573492 16297 solver.cpp:294] Iteration 86000, Testing net (#0)
I0812 10:54:06.573526 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.573545 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.573565 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.574792 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.574812 16297 solver.cpp:343]     Test net output #1: loss = 0.29792 (* 1 = 0.29792 loss)
I0812 10:54:06.574836 16297 solver.cpp:214] Iteration 86000, loss = 0.292646
I0812 10:54:06.574851 16297 solver.cpp:229]     Train net output #0: loss = 0.292646 (* 1 = 0.292646 loss)
I0812 10:54:06.574861 16297 solver.cpp:486] Iteration 86000, lr = 1e-05
I0812 10:54:06.580018 16297 solver.cpp:214] Iteration 86500, loss = 0.292548
I0812 10:54:06.580054 16297 solver.cpp:229]     Train net output #0: loss = 0.292548 (* 1 = 0.292548 loss)
I0812 10:54:06.580063 16297 solver.cpp:486] Iteration 86500, lr = 1e-05
I0812 10:54:06.585142 16297 solver.cpp:294] Iteration 87000, Testing net (#0)
I0812 10:54:06.585178 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.585186 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.585199 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.586390 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.586416 16297 solver.cpp:343]     Test net output #1: loss = 0.298519 (* 1 = 0.298519 loss)
I0812 10:54:06.586441 16297 solver.cpp:214] Iteration 87000, loss = 0.29245
I0812 10:54:06.586455 16297 solver.cpp:229]     Train net output #0: loss = 0.29245 (* 1 = 0.29245 loss)
I0812 10:54:06.586465 16297 solver.cpp:486] Iteration 87000, lr = 1e-05
I0812 10:54:06.591541 16297 solver.cpp:214] Iteration 87500, loss = 0.292353
I0812 10:54:06.591604 16297 solver.cpp:229]     Train net output #0: loss = 0.292353 (* 1 = 0.292353 loss)
I0812 10:54:06.591614 16297 solver.cpp:486] Iteration 87500, lr = 1e-05
I0812 10:54:06.596776 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.596827 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_88000.caffemodel
I0812 10:54:06.597002 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_88000.solverstate
I0812 10:54:06.597121 16297 solver.cpp:294] Iteration 88000, Testing net (#0)
I0812 10:54:06.597146 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.597153 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.597178 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.598399 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.598426 16297 solver.cpp:343]     Test net output #1: loss = 0.296221 (* 1 = 0.296221 loss)
I0812 10:54:06.598454 16297 solver.cpp:214] Iteration 88000, loss = 0.292255
I0812 10:54:06.598469 16297 solver.cpp:229]     Train net output #0: loss = 0.292255 (* 1 = 0.292255 loss)
I0812 10:54:06.598481 16297 solver.cpp:486] Iteration 88000, lr = 1e-05
I0812 10:54:06.603561 16297 solver.cpp:214] Iteration 88500, loss = 0.292157
I0812 10:54:06.603588 16297 solver.cpp:229]     Train net output #0: loss = 0.292157 (* 1 = 0.292157 loss)
I0812 10:54:06.603610 16297 solver.cpp:486] Iteration 88500, lr = 1e-05
I0812 10:54:06.608675 16297 solver.cpp:294] Iteration 89000, Testing net (#0)
I0812 10:54:06.608696 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.608716 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.608724 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.610013 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.610033 16297 solver.cpp:343]     Test net output #1: loss = 0.297218 (* 1 = 0.297218 loss)
I0812 10:54:06.610079 16297 solver.cpp:214] Iteration 89000, loss = 0.29206
I0812 10:54:06.610092 16297 solver.cpp:229]     Train net output #0: loss = 0.29206 (* 1 = 0.29206 loss)
I0812 10:54:06.610112 16297 solver.cpp:486] Iteration 89000, lr = 1e-05
I0812 10:54:06.615195 16297 solver.cpp:214] Iteration 89500, loss = 0.291962
I0812 10:54:06.615217 16297 solver.cpp:229]     Train net output #0: loss = 0.291962 (* 1 = 0.291962 loss)
I0812 10:54:06.615226 16297 solver.cpp:486] Iteration 89500, lr = 1e-05
I0812 10:54:06.620229 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.620267 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_90000.caffemodel
I0812 10:54:06.620475 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_90000.solverstate
I0812 10:54:06.620666 16297 solver.cpp:294] Iteration 90000, Testing net (#0)
I0812 10:54:06.620700 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.620708 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.620720 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.622006 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.622030 16297 solver.cpp:343]     Test net output #1: loss = 0.297823 (* 1 = 0.297823 loss)
I0812 10:54:06.622057 16297 solver.cpp:214] Iteration 90000, loss = 0.291865
I0812 10:54:06.622072 16297 solver.cpp:229]     Train net output #0: loss = 0.291865 (* 1 = 0.291865 loss)
I0812 10:54:06.622084 16297 solver.cpp:486] Iteration 90000, lr = 1e-05
I0812 10:54:06.627101 16297 solver.cpp:214] Iteration 90500, loss = 0.291768
I0812 10:54:06.627130 16297 solver.cpp:229]     Train net output #0: loss = 0.291768 (* 1 = 0.291768 loss)
I0812 10:54:06.627140 16297 solver.cpp:486] Iteration 90500, lr = 1e-05
I0812 10:54:06.632143 16297 solver.cpp:294] Iteration 91000, Testing net (#0)
I0812 10:54:06.632163 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.632171 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.632181 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.633420 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.633460 16297 solver.cpp:343]     Test net output #1: loss = 0.295531 (* 1 = 0.295531 loss)
I0812 10:54:06.633497 16297 solver.cpp:214] Iteration 91000, loss = 0.291671
I0812 10:54:06.633512 16297 solver.cpp:229]     Train net output #0: loss = 0.291671 (* 1 = 0.291671 loss)
I0812 10:54:06.633533 16297 solver.cpp:486] Iteration 91000, lr = 1e-05
I0812 10:54:06.638617 16297 solver.cpp:214] Iteration 91500, loss = 0.291574
I0812 10:54:06.638653 16297 solver.cpp:229]     Train net output #0: loss = 0.291574 (* 1 = 0.291574 loss)
I0812 10:54:06.638663 16297 solver.cpp:486] Iteration 91500, lr = 1e-05
I0812 10:54:06.643721 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.643766 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_92000.caffemodel
I0812 10:54:06.643955 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_92000.solverstate
I0812 10:54:06.644075 16297 solver.cpp:294] Iteration 92000, Testing net (#0)
I0812 10:54:06.644099 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.644109 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.644119 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.645356 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.645400 16297 solver.cpp:343]     Test net output #1: loss = 0.296523 (* 1 = 0.296523 loss)
I0812 10:54:06.645424 16297 solver.cpp:214] Iteration 92000, loss = 0.291477
I0812 10:54:06.645469 16297 solver.cpp:229]     Train net output #0: loss = 0.291477 (* 1 = 0.291477 loss)
I0812 10:54:06.645481 16297 solver.cpp:486] Iteration 92000, lr = 1e-05
I0812 10:54:06.650539 16297 solver.cpp:214] Iteration 92500, loss = 0.29138
I0812 10:54:06.650568 16297 solver.cpp:229]     Train net output #0: loss = 0.29138 (* 1 = 0.29138 loss)
I0812 10:54:06.650578 16297 solver.cpp:486] Iteration 92500, lr = 1e-05
I0812 10:54:06.655582 16297 solver.cpp:294] Iteration 93000, Testing net (#0)
I0812 10:54:06.655602 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.655611 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.655618 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.656900 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.656934 16297 solver.cpp:343]     Test net output #1: loss = 0.297134 (* 1 = 0.297134 loss)
I0812 10:54:06.656958 16297 solver.cpp:214] Iteration 93000, loss = 0.291283
I0812 10:54:06.656985 16297 solver.cpp:229]     Train net output #0: loss = 0.291283 (* 1 = 0.291283 loss)
I0812 10:54:06.656996 16297 solver.cpp:486] Iteration 93000, lr = 1e-05
I0812 10:54:06.662147 16297 solver.cpp:214] Iteration 93500, loss = 0.291187
I0812 10:54:06.662178 16297 solver.cpp:229]     Train net output #0: loss = 0.291187 (* 1 = 0.291187 loss)
I0812 10:54:06.662189 16297 solver.cpp:486] Iteration 93500, lr = 1e-05
I0812 10:54:06.667292 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.667330 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_94000.caffemodel
I0812 10:54:06.667501 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_94000.solverstate
I0812 10:54:06.667649 16297 solver.cpp:294] Iteration 94000, Testing net (#0)
I0812 10:54:06.667673 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.667682 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.667691 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.668932 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.668964 16297 solver.cpp:343]     Test net output #1: loss = 0.294847 (* 1 = 0.294847 loss)
I0812 10:54:06.668989 16297 solver.cpp:214] Iteration 94000, loss = 0.29109
I0812 10:54:06.669004 16297 solver.cpp:229]     Train net output #0: loss = 0.29109 (* 1 = 0.29109 loss)
I0812 10:54:06.669015 16297 solver.cpp:486] Iteration 94000, lr = 1e-05
I0812 10:54:06.674176 16297 solver.cpp:214] Iteration 94500, loss = 0.290994
I0812 10:54:06.674207 16297 solver.cpp:229]     Train net output #0: loss = 0.290994 (* 1 = 0.290994 loss)
I0812 10:54:06.674219 16297 solver.cpp:486] Iteration 94500, lr = 1e-05
I0812 10:54:06.679236 16297 solver.cpp:294] Iteration 95000, Testing net (#0)
I0812 10:54:06.679256 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.679265 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.679272 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.680529 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.680551 16297 solver.cpp:343]     Test net output #1: loss = 0.295833 (* 1 = 0.295833 loss)
I0812 10:54:06.680593 16297 solver.cpp:214] Iteration 95000, loss = 0.290897
I0812 10:54:06.680619 16297 solver.cpp:229]     Train net output #0: loss = 0.290897 (* 1 = 0.290897 loss)
I0812 10:54:06.680672 16297 solver.cpp:486] Iteration 95000, lr = 1e-05
I0812 10:54:06.685714 16297 solver.cpp:214] Iteration 95500, loss = 0.290801
I0812 10:54:06.685741 16297 solver.cpp:229]     Train net output #0: loss = 0.290801 (* 1 = 0.290801 loss)
I0812 10:54:06.685751 16297 solver.cpp:486] Iteration 95500, lr = 1e-05
I0812 10:54:06.690868 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.690910 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_96000.caffemodel
I0812 10:54:06.691076 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_96000.solverstate
I0812 10:54:06.691211 16297 solver.cpp:294] Iteration 96000, Testing net (#0)
I0812 10:54:06.691244 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.691256 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.691264 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.692550 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.692581 16297 solver.cpp:343]     Test net output #1: loss = 0.296448 (* 1 = 0.296448 loss)
I0812 10:54:06.692605 16297 solver.cpp:214] Iteration 96000, loss = 0.290705
I0812 10:54:06.692641 16297 solver.cpp:229]     Train net output #0: loss = 0.290705 (* 1 = 0.290705 loss)
I0812 10:54:06.692651 16297 solver.cpp:486] Iteration 96000, lr = 1e-05
I0812 10:54:06.697702 16297 solver.cpp:214] Iteration 96500, loss = 0.290608
I0812 10:54:06.697726 16297 solver.cpp:229]     Train net output #0: loss = 0.290608 (* 1 = 0.290608 loss)
I0812 10:54:06.697736 16297 solver.cpp:486] Iteration 96500, lr = 1e-05
I0812 10:54:06.702720 16297 solver.cpp:294] Iteration 97000, Testing net (#0)
I0812 10:54:06.702738 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.702744 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.702752 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.704082 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.704154 16297 solver.cpp:343]     Test net output #1: loss = 0.294166 (* 1 = 0.294166 loss)
I0812 10:54:06.704217 16297 solver.cpp:214] Iteration 97000, loss = 0.290512
I0812 10:54:06.704251 16297 solver.cpp:229]     Train net output #0: loss = 0.290512 (* 1 = 0.290512 loss)
I0812 10:54:06.704277 16297 solver.cpp:486] Iteration 97000, lr = 1e-05
I0812 10:54:06.709421 16297 solver.cpp:214] Iteration 97500, loss = 0.290417
I0812 10:54:06.709460 16297 solver.cpp:229]     Train net output #0: loss = 0.290417 (* 1 = 0.290417 loss)
I0812 10:54:06.709471 16297 solver.cpp:486] Iteration 97500, lr = 1e-05
I0812 10:54:06.714506 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.714553 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_98000.caffemodel
I0812 10:54:06.714754 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_98000.solverstate
I0812 10:54:06.714890 16297 solver.cpp:294] Iteration 98000, Testing net (#0)
I0812 10:54:06.714922 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.714952 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.714962 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.716217 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.716244 16297 solver.cpp:343]     Test net output #1: loss = 0.295147 (* 1 = 0.295147 loss)
I0812 10:54:06.716271 16297 solver.cpp:214] Iteration 98000, loss = 0.290321
I0812 10:54:06.716286 16297 solver.cpp:229]     Train net output #0: loss = 0.290321 (* 1 = 0.290321 loss)
I0812 10:54:06.716297 16297 solver.cpp:486] Iteration 98000, lr = 1e-05
I0812 10:54:06.721382 16297 solver.cpp:214] Iteration 98500, loss = 0.290225
I0812 10:54:06.721458 16297 solver.cpp:229]     Train net output #0: loss = 0.290225 (* 1 = 0.290225 loss)
I0812 10:54:06.721485 16297 solver.cpp:486] Iteration 98500, lr = 1e-05
I0812 10:54:06.726553 16297 solver.cpp:294] Iteration 99000, Testing net (#0)
I0812 10:54:06.726572 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.726582 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.726615 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.727938 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.727972 16297 solver.cpp:343]     Test net output #1: loss = 0.295767 (* 1 = 0.295767 loss)
I0812 10:54:06.727998 16297 solver.cpp:214] Iteration 99000, loss = 0.29013
I0812 10:54:06.728013 16297 solver.cpp:229]     Train net output #0: loss = 0.29013 (* 1 = 0.29013 loss)
I0812 10:54:06.728023 16297 solver.cpp:486] Iteration 99000, lr = 1e-05
I0812 10:54:06.733026 16297 solver.cpp:214] Iteration 99500, loss = 0.290035
I0812 10:54:06.733053 16297 solver.cpp:229]     Train net output #0: loss = 0.290035 (* 1 = 0.290035 loss)
I0812 10:54:06.733063 16297 solver.cpp:486] Iteration 99500, lr = 1e-05
I0812 10:54:06.738144 16297 net.cpp:763] Serializing 3 layers
I0812 10:54:06.738260 16297 solver.cpp:361] Snapshotting to /home/abba/caffe/examples/simple/simple_iter_100000.caffemodel
I0812 10:54:06.738466 16297 solver.cpp:369] Snapshotting solver state to /home/abba/caffe/examples/simple/simple_iter_100000.solverstate
I0812 10:54:06.738615 16297 solver.cpp:276] Iteration 100000, loss = 0.289939
I0812 10:54:06.738636 16297 solver.cpp:294] Iteration 100000, Testing net (#0)
I0812 10:54:06.738643 16297 net.cpp:671] Copying source layer data
I0812 10:54:06.738652 16297 net.cpp:671] Copying source layer fc1
I0812 10:54:06.738662 16297 net.cpp:671] Copying source layer loss
I0812 10:54:06.739907 16297 solver.cpp:343]     Test net output #0: accuracy = 1
I0812 10:54:06.739929 16297 solver.cpp:343]     Test net output #1: loss = 0.29349 (* 1 = 0.29349 loss)
I0812 10:54:06.739941 16297 solver.cpp:281] Optimization Done.
I0812 10:54:06.739950 16297 caffe.cpp:134] Optimization Done.
